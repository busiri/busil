{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/busiri/busil/blob/main/3%EB%8B%A8%EA%B3%84(%EB%B6%84%EB%A6%AC%20%EB%B0%8F%20%EA%B2%B0%EC%B8%A1%EC%B9%98%20%EC%B2%98%EB%A6%AC).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKWZ--WLQ4Eb"
      },
      "source": [
        "### 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXeiOa0AAL-S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from scipy.stats.mstats import winsorize\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "\n",
        "phase_files = {\n",
        "    '도입': 'eda도입.csv',\n",
        "    '성장': 'eda성장.csv',\n",
        "    '성숙': 'eda성숙.csv',\n",
        "    '쇠퇴': 'eda쇠퇴.csv'\n",
        "}\n",
        "\n",
        "for phase, file in phase_files.items():\n",
        "    df = pd.read_csv(file)\n",
        "    print(f\"[{phase}] 원본 데이터 shape: {df.shape}\")\n",
        "    # 결측치 개수 확인\n",
        "    print(f\"[{phase}] 결측치 개수:\")\n",
        "    print(df.isna().sum()[df.isna().sum() > 0])\n",
        "    # 결측치 제거(행)\n",
        "    df = df.dropna(axis=0, how='any')\n",
        "    print(f\"[{phase}] 결측치 제거 후 shape: {df.shape}\")\n",
        "    # train/test 분리\n",
        "    train_df, test_df = train_test_split(\n",
        "        df, test_size=0.2, random_state=42, stratify=df['부실여부']\n",
        "    )\n",
        "    train_df.to_csv(f'{phase}_train.csv', index=False)\n",
        "    test_df.to_csv(f'{phase}_test.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NutfRJ3qa1E"
      },
      "source": [
        "### 파생변수 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hPnhcKMqcXN"
      },
      "outputs": [],
      "source": [
        "def add_derived_vars_no_lag(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    # 0) 로그 → 원본 복원 (필요 시)\n",
        "    if '로그매출액' in df.columns:\n",
        "        df['매출액(천원)'] = np.exp(df['로그매출액'])\n",
        "        df.drop(columns=['로그매출액'], inplace=True)\n",
        "    if '로그자산' in df.columns:\n",
        "        df['자산(천원)'] = np.exp(df['로그자산'])\n",
        "        df.drop(columns=['로그자산'], inplace=True)\n",
        "\n",
        "    # 안전 나눗셈 도우미\n",
        "    def safe_div(num, denom):\n",
        "        return np.where(denom == 0, np.nan, num / denom)\n",
        "\n",
        "    # --- 1) 수익성 지표\n",
        "    df['/ 매출원가/매출액 비율']    = safe_div(df['매출원가(천원)'], df['매출액(천원)'])\n",
        "    df['/ 사내유보율']            = safe_div(df['이익잉여금(천원)'], df['자본(천원)'])\n",
        "\n",
        "    # --- 2) 활동성·효율성 지표\n",
        "    net_wc = df['유동자산(천원)'] - df['유동부채(천원)']\n",
        "    df['/ 재고/순운전자본 비율']   = safe_div(df['재고자산(천원)'], net_wc)\n",
        "    df['/ 비유동부채/순운전자본 비율'] = safe_div(df['부채(천원)'] - df['유동부채(천원)'], net_wc)\n",
        "    df['/ 자기자본회전률']        = safe_div(df['매출액(천원)'], df['자본(천원)'])\n",
        "    df['/ 재고자산회전률']        = safe_div(df['매출원가(천원)'], df['재고자산(천원)'])\n",
        "    df['/ 재고자산회전기간']      = safe_div(365, safe_div(df['매출원가(천원)'], df['재고자산(천원)']))\n",
        "    df['/ 운전자본회전률']        = safe_div(df['매출액(천원)'], net_wc)\n",
        "    df['/ 1회전기간']            = safe_div(365, safe_div(df['매출액(천원)'], net_wc))\n",
        "\n",
        "    # --- 3) 인력·노동 생산성 지표\n",
        "    df['/ 종업원1인당 부가가치(백만원)'] = safe_div(df['부가가치(백만원)'], df['종업원'])\n",
        "    df['/ 종업원1인당 매출액(백만원)'] = safe_div(df['매출액(천원)'], df['종업원'])\n",
        "    df['/ 종업원당영업이익(백만원)']   = safe_div(df['영업이익(손실)(천원)'], df['종업원']) / 1e3\n",
        "    df['/ 종업원1인당 순이익(백만원)'] = safe_div(df['당기순이익(손실)(천원)'], df['종업원']) / 1e3\n",
        "    df['/ 종업원1인당 인건비(백만원)'] = safe_div(df['급여(천원)'], df['종업원']) / 1e3\n",
        "    df['/ 노동소득분배율']          = safe_div(df['급여(천원)'], df['부가가치(백만원)'] * 1e3)\n",
        "\n",
        "    # --- 4) 자본집약도 지표\n",
        "    df['/ 자본집약도']            = safe_div(df['자산(천원)'], df['종업원'])\n",
        "\n",
        "    # --- 5) 기존 파생변수: 안정성·레버리지·현금흐름·투하자본수익률\n",
        "    # 5-1) 안정성 비율\n",
        "    df['/ 현금/총자산 비율']      = safe_div(df['현금및현금성자산(천원)'], df['자산(천원)'])\n",
        "    df['/ 이익잉여금/총자산 비율'] = safe_div(df['이익잉여금(천원)'], df['자산(천원)'])\n",
        "    df['/ 급여/총자산 비율']      = safe_div(df['급여(천원)'], df['자산(천원)'])\n",
        "\n",
        "    # 5-2) 비용·레버리지·효율\n",
        "    df['/ 급여/매출액 비율']      = safe_div(df['급여(천원)'], df['매출액(천원)'])\n",
        "    df['/ 업력 효율지수']         = safe_div(df['매출액(천원)'], df['업력'])\n",
        "    df['/ 매출원가/부채 비율']    = safe_div(df['매출원가(천원)'], df['부채(천원)'])\n",
        "    df['/ 급여/세전순익 비율']    = safe_div(df['급여(천원)'], df['법인세비용차감전손익(천원)'])\n",
        "    df['/ 재무 레버리지']        = safe_div(\n",
        "        df['영업이익(손실)(천원)'],\n",
        "        df['영업이익(손실)(천원)'] - df['이자비용(천원)']\n",
        "    )\n",
        "\n",
        "    # 5-3) 금융비용 부담률\n",
        "    df['/ 금융비용부담률']        = safe_div(df['이자비용(천원)'], df['매출액(천원)'])\n",
        "\n",
        "    # 5-4) 현금흐름 변수\n",
        "    df['/ 영업CF/자산 비율']      = safe_div(df['영업현금흐름(천원)'], df['자산(천원)'])\n",
        "    df['/ 투자CF/자산 비율']      = safe_div(df['투자활동으로 인한 현금흐름(*)(천원)'], df['자산(천원)'])\n",
        "    df['/ 영업CF/유동부채 비율']   = safe_div(df['영업현금흐름(천원)'], df['유동부채(천원)'])\n",
        "    # 총차입금이 없으면 부채(천원) 사용\n",
        "    total_borrow = df['총차입금'] if '총차입금' in df.columns else df['부채(천원)']\n",
        "    df['/ 재무CF/총차입금 비율']   = safe_div(df['재무활동으로 인한 현금흐름(*)(천원)'], total_borrow)\n",
        "\n",
        "    # 5-5) 통합현금흐름 긍정여부\n",
        "    cf_sum = (\n",
        "        df['영업현금흐름(천원)']\n",
        "      + df['투자활동으로 인한 현금흐름(*)(천원)']\n",
        "      + df['재무활동으로 인한 현금흐름(*)(천원)']\n",
        "    )\n",
        "    df['/ 현금흐름통합_긍정여부'] = np.where(cf_sum > 0, 1, 0)\n",
        "    df['/ 현금흐름통합_긍정여부'] = df['/ 현금흐름통합_긍정여부'].astype('object')\n",
        "    # 5-6) 투하자본수익률 (영업이익 ÷ (자본+부채) ×100)\n",
        "    total_cap = df['자본(천원)'] + df['부채(천원)']\n",
        "    df['/ 투하자본수익률']       = safe_div(df['영업이익(손실)(천원)'], total_cap) * 100\n",
        "\n",
        "    # 7) EBIT\n",
        "    df['/ EBIT'] = df['법인세비용차감전손익(천원)'] + df['이자비용(천원)']\n",
        "    df['/ EBIT / 자산'] = safe_div(df['/ EBIT'], df['자산(천원)'])\n",
        "    df['/ EBIT / 매출액'] = safe_div(df['/ EBIT'], df['매출액(천원)'])\n",
        "    df['/ EBIT / 영업현금흐름(천원)'] = safe_div(df['/ EBIT'], df['영업현금흐름(천원)'])\n",
        "\n",
        "    # 8)\n",
        "    df['/ 잉여현금흐름(FCF)'] = (df['영업현금흐름(천원)'] - df['투자활동으로 인한 현금흐름(*)(천원)'])\n",
        "    df['/ 이익잉여금/부채 비율'] = safe_div(df['이익잉여금(천원)'],df['부채(천원)'])\n",
        "    df['/ 잉여현금흐름 / 자산 비율'] = safe_div(df['/ 잉여현금흐름(FCF)'], df['자산(천원)'])\n",
        "\n",
        "    # 9) 업력\n",
        "    df['/ 업력_범주12'] = df['업력'].map(lambda x: 1 if x > 12 else 0)\n",
        "    df['/ 업력_범주12'] = df['/ 업력_범주12'].astype('object')\n",
        "\n",
        "    # 10) 무한대 → NaN\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    # 파생변수에 사용된 컬럼 제거\n",
        "    drop_cols = ['매출액(천원)','자산(천원)','매출원가(천원)','자본(천원)','유동자산(천원)', '유동부채(천원)','재고자산(천원)',\n",
        "                '부채(천원)','유동부채(천원)','부가가치(백만원)','종업원','영업이익(손실)(천원)','당기순이익(손실)(천원)','급여(천원)',\n",
        "                '업력','법인세비용차감전손익(천원)','이자비용(천원)','영업현금흐름(천원)','투자활동으로 인한 현금흐름(*)(천원)',\n",
        "                '재무활동으로 인한 현금흐름(*)(천원)','/ EBIT','이익잉여금(천원)','/ 잉여현금흐름(FCF)','업력']\n",
        "\n",
        "    df.drop(columns=drop_cols,inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def make_variable(df1,df2):\n",
        "\n",
        "  # 거래소코드와 회사명을 활용하여 기업ID 컬럼 생성\n",
        "  df1 = df1.sort_values(by=['거래소코드', '회사명', '회계년도']).reset_index(drop=True)\n",
        "  df2 = df2.sort_values(by=['거래소코드', '회사명', '회계년도']).reset_index(drop=True)\n",
        "  df1['기업ID'] = df1['거래소코드'].astype(str) + \"_\" + df1['회사명'].astype(str)\n",
        "  df2['기업ID'] = df2['거래소코드'].astype(str) + \"_\" + df2['회사명'].astype(str)\n",
        "\n",
        "  # 수치형 컬럼 중 결측 적고 분산 큰 것 상위 100개 선정\n",
        "  object_cols = df1.select_dtypes(include='object').columns\n",
        "  df1_obj = df[object_cols]\n",
        "  df2_obj = df[object_cols]\n",
        "  num_cols = df1.select_dtypes(include=['float64', 'int64']).copy()\n",
        "  valid_cols = num_cols.columns[num_cols.isnull().mean() < 0.3]\n",
        "  sorted_cols = num_cols[valid_cols].var().sort_values(ascending=False).index\n",
        "  top_100_cols = sorted_cols[:100].tolist()\n",
        "\n",
        "  # 파생변수 생성\n",
        "  for col in top_100_cols:\n",
        "      try:\n",
        "          print(f\"Processing: {col}\")\n",
        "          grouped = df1.groupby('기업ID')\n",
        "          grouped2 = df2.groupby('기업ID')\n",
        "          c0 = grouped[col].shift(0)\n",
        "          c1 = grouped[col].shift(1)\n",
        "          c2 = grouped[col].shift(2)\n",
        "          c3 = grouped[col].shift(3)\n",
        "          test_c0 = grouped2[col].shift(0)\n",
        "          test_c1 = grouped2[col].shift(1)\n",
        "          test_c2 = grouped2[col].shift(2)\n",
        "          test_c3 = grouped2[col].shift(3)\n",
        "\n",
        "          df1[f'{col}_inc_2yr'] = ((c1 < c0) & (c2 < c1)).astype('object')\n",
        "          df2[f'{col}_inc_2yr'] = ((test_c1 < test_c0) & (test_c2 < test_c1)).astype('object')\n",
        "\n",
        "          df1[f'{col}_dec_2yr'] = ((c1 > c0) & (c2 > c1)).astype('object')\n",
        "          df2[f'{col}_dec_2yr'] = ((test_c1 > test_c0) & (test_c2 > test_c1)).astype('object')\n",
        "\n",
        "          df1[f'{col}_inc_3yr'] = ((c2 < c1) & (c1 < c0)).astype('object')\n",
        "          df2[f'{col}_inc_3yr'] = ((test_c2 < test_c1) & (test_c1 < test_c0)).astype('object')\n",
        "\n",
        "          df1[f'{col}_dec_3yr'] = ((c2 > c1) & (c1 > c0)).astype('object')\n",
        "          df2[f'{col}_dec_3yr'] = ((test_c2 > test_c1) & (test_c1 > test_c0)).astype('object')\n",
        "\n",
        "          df1[f'{col}_inc_4yr'] = ((c3 < c2) & (c2 < c1) & (c1 < c0)).astype('object')\n",
        "          df2[f'{col}_inc_4yr'] = ((test_c3 < test_c2) & (test_c2 < test_c1) & (test_c1 < test_c0)).astype('object')\n",
        "\n",
        "          df1[f'{col}_dec_4yr'] = ((c3 > c2) & (c2 > c1) & (c1 > c0)).astype('object')\n",
        "          df2[f'{col}_dec_4yr'] = ((test_c3 > test_c2) & (test_c2 > test_c1) & (test_c1 > test_c0)).astype('object')\n",
        "\n",
        "          diff1 = grouped[col].diff()\n",
        "          diff2 = grouped2[col].diff()\n",
        "          df1[f'{col}_mean_diff_3yr'] = diff1.rolling(3, min_periods=1).mean()\n",
        "          df2[f'{col}_mean_diff_3yr'] = diff2.rolling(3, min_periods=1).mean()\n",
        "\n",
        "          df1[f'{col}_pos_2yr'] = ((c1 > 0) & (c0 > 0)).astype('object')\n",
        "          df2[f'{col}_pos_2yr'] = ((test_c1 > 0) & (test_c0 > 0)).astype('object')\n",
        "\n",
        "          df1[f'{col}_dec_count'] = grouped[col].diff1().lt(0).groupby(df1['기업ID']).cumsum().astype('object')\n",
        "          df2[f'{col}_dec_count'] = grouped2[col].diff2().lt(0).groupby(df2['기업ID']).cumsum().astype('object')\n",
        "      except Exception as e:\n",
        "          print(f\"⚠️ Error processing {col}: {e}\")\n",
        "\n",
        "  df1 = pd.concat([df1,df1_obj],axis=1)\n",
        "  df2 = pd.concat([df2,df2_obj],axis=1)\n",
        "  return df1, df2\n",
        "\n",
        "for phase in phase_files:\n",
        "    train_df = pd.read_csv(f'{phase}_train.csv')\n",
        "    test_df = pd.read_csv(f'{phase}_test.csv')\n",
        "    train_df_derived = add_derived_vars_no_lag(train_df)\n",
        "    test_df_derived = add_derived_vars_no_lag(test_df)\n",
        "    train_df_derived,test_df_derived = make_variable(train_df_derived,test_df_derived)\n",
        "    train_df_derived.to_csv(f'{phase}_train_파생.csv', index=False)\n",
        "    test_df_derived.to_csv(f'{phase}_test_파생.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7ubWwSRcju8"
      },
      "source": [
        "### 0 비율이 높은 컬럼 및 주식과 관련 된 컬럼 제거\n",
        "- 외감기업이 대부분이라 신뢰성 있는 주식 관련 컬럼 데이터를 확보할 수 없다고\n",
        "판단"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBKESV4sq3o4"
      },
      "outputs": [],
      "source": [
        "# 각 국면별 0비율이 높은 컬럼 제거\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 제거할 컬럼 리스트\n",
        "cols_to_remove = [\n",
        "    '대표이사변경여부', '상장폐지일', '종업원1인당 인건비(백만원)', '종업원1인당 순이익(백만원)',\n",
        "    '종업원당영업이익(백만원)', '종업원1인당 매출액(백만원)', '종업원1인당 부가가치(백만원)',\n",
        "    '종업원1인당 인건비증가율', '종업원1인당 매출액증가율', '종업원수증가율',\n",
        "    '종업원1인당 부가가치증가율', '사내유보율', '배당성향', '노동장비율', '기계장비율','자본집약도','평균배당률','1주당매출액(원)','유보율','자기자본배당률'\n",
        "]\n",
        "\n",
        "phase_files = [\n",
        "    ('도입_train_파생_dropna.csv', '도입'),\n",
        "    ('성장_train_파생_dropna.csv', '성장'),\n",
        "    ('성숙_train_파생_dropna.csv', '성숙'),\n",
        "    ('쇠퇴_train_파생_dropna.csv', '쇠퇴')\n",
        "]\n",
        "\n",
        "for file, label in phase_files:\n",
        "    df = pd.read_csv(file)\n",
        "    # 실제로 존재하는 컬럼만 제거\n",
        "    remove_cols = [col for col in cols_to_remove if col in df.columns]\n",
        "    if remove_cols:\n",
        "        print(f\"[{label}] 제거할 컬럼: {remove_cols}\")\n",
        "        df = df.drop(columns=remove_cols)\n",
        "    else:\n",
        "        print(f\"[{label}] 제거할 컬럼 없음\")\n",
        "    save_name = f\"{label}_train_파생_컬럼제거.csv\"\n",
        "    df.to_csv(save_name, index=False)\n",
        "    print(f\"[{label}] 저장 완료: {save_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9FkGTbEuClB"
      },
      "source": [
        "### 이상치 처리 : 상/하위 1% 윈저라이징"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq95jV0tq-76"
      },
      "outputs": [],
      "source": [
        "from scipy.stats.mstats import winsorize\n",
        "import pandas as pd\n",
        "\n",
        "def apply_winsorize(series, limits=(0.01, 0.01)):\n",
        "    return winsorize(series, limits=limits)\n",
        "\n",
        "for phase in ['도입', '성장', '성숙', '쇠퇴']:\n",
        "    train_df_derived = pd.read_csv(f'{phase}_train_파생_컬럼제거.csv')\n",
        "    # 수치형 컬럼 중 범주형 변수(cat_cols)와 '부실여부'는 제외\n",
        "    cat_cols = train_df_derived.select_dtypes(include='object').columns\n",
        "    num_cols = train_df_derived.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    num_cols = [col for col in num_cols if col != '부실여부' and col not in cat_cols]\n",
        "    train_df_winsor = train_df_derived.copy()\n",
        "    for col in num_cols:\n",
        "        train_df_winsor[col] = apply_winsorize(train_df_derived[col], limits=(0.01, 0.01))\n",
        "    train_df_winsor.to_csv(f'{phase}_train_파생_winsor.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddvIQF6lEBYk"
      },
      "source": [
        "### 결측치 처리 : 회사 그룹별로 데이터가 있으면 회사 중앙값\n",
        "- 결측치 문제를 완벽히 해결하지 못해서 이 방법을 쓰지는 않았습니다\n",
        "- 결측치는 우선 0과 NaN 비율이 높은 컬럼을 제거한 뒤 행 단위 제거 방식으로 진행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR0aPMQ_Netz"
      },
      "source": [
        "## 수치형"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8ZIH6JIxugS",
        "outputId": "1df7d302-6aae-4519-b67b-88e0394a4c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "도입기 훈련 데이터 결측치 수 : 2477, 도입기 평가 데이터 결측치 수 : 1155\n",
            "성장기 훈련 데이터 결측치 수 : 4816, 성장기 평가 데이터 결측치 수 : 1440\n",
            "성숙기 훈련 데이터 결측치 수 : 5087, 성숙기 평가 데이터 결측치 수 : 1801\n",
            "쇠퇴기 훈련 데이터 결측치 수 : 1317, 쇠퇴기 평가 데이터 결측치 수 : 653\n"
          ]
        }
      ],
      "source": [
        "numeric_cols1 = train_도입.select_dtypes(include=[np.number]).columns\n",
        "numeric_cols2 = train_성장.select_dtypes(include=[np.number]).columns\n",
        "numeric_cols3 = train_성숙.select_dtypes(include=[np.number]).columns\n",
        "numeric_cols4 = train_쇠퇴.select_dtypes(include=[np.number]).columns\n",
        "print(f\"도입기 훈련 데이터 결측치 수 : {train_도입[numeric_cols1].isna().sum().sum()}, 도입기 평가 데이터 결측치 수 : {test_도입[numeric_cols1].isna().sum().sum()}\")\n",
        "print(f\"성장기 훈련 데이터 결측치 수 : {train_성장[numeric_cols2].isna().sum().sum()}, 성장기 평가 데이터 결측치 수 : {test_성장[numeric_cols2].isna().sum().sum()}\")\n",
        "print(f\"성숙기 훈련 데이터 결측치 수 : {train_성숙[numeric_cols3].isna().sum().sum()}, 성숙기 평가 데이터 결측치 수 : {test_성숙[numeric_cols3].isna().sum().sum()}\")\n",
        "print(f\"쇠퇴기 훈련 데이터 결측치 수 : {train_쇠퇴[numeric_cols4].isna().sum().sum()}, 쇠퇴기 평가 데이터 결측치 수 : {test_쇠퇴[numeric_cols4].isna().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI3ODag0eJce"
      },
      "source": [
        "### 그룹화 후 중앙값으로 대체하는 방식(사용하지 못함)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZSMxRA3EAXk",
        "outputId": "8754bda7-fd25-466f-e0fb-85f5a25a92ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21275/21275 [00:10<00:00, 2061.10it/s]\n",
            "100%|██████████| 8463/8463 [00:04<00:00, 1732.90it/s]\n",
            "100%|██████████| 32453/32453 [00:16<00:00, 1996.89it/s]\n",
            "100%|██████████| 10795/10795 [00:05<00:00, 1875.57it/s]\n",
            "100%|██████████| 44467/44467 [00:25<00:00, 1778.27it/s]\n",
            "100%|██████████| 13644/13644 [00:06<00:00, 2194.51it/s]\n",
            "100%|██████████| 8928/8928 [00:03<00:00, 2590.88it/s]\n",
            "100%|██████████| 4796/4796 [00:03<00:00, 1467.19it/s]\n"
          ]
        }
      ],
      "source": [
        "# tqdm 설정\n",
        "tqdm.pandas()\n",
        "\n",
        "def fill_na(df):\n",
        "    group_cols = ['회사명', '거래소코드']\n",
        "    numeric_cols = df.select_dtypes(include='number').columns\n",
        "\n",
        "    # 그룹별 중앙값 계산\n",
        "    group_medians = df.groupby(group_cols)[numeric_cols].median()\n",
        "\n",
        "    # 각 행에 대해 결측치를 중앙값으로 채움 (단, 중앙값이 NaN이면 그대로 둠)\n",
        "    def fill_with_group_median(row):\n",
        "        key = (row['회사명'], row['거래소코드'])\n",
        "        if key in group_medians.index:\n",
        "            for col in numeric_cols:\n",
        "                if pd.isna(row[col]):\n",
        "                    median_val = group_medians.loc[key, col]\n",
        "                    if not pd.isna(median_val):\n",
        "                        row[col] = median_val\n",
        "        return row\n",
        "\n",
        "    # 진행률 표시하면서 적용\n",
        "    df = df.progress_apply(fill_with_group_median, axis=1)\n",
        "    return df\n",
        "\n",
        "# 학습/테스트 리스트\n",
        "result = []\n",
        "for train, test in zip(train_list, test_list):\n",
        "    train = fill_na(train)\n",
        "    test = fill_na(test)\n",
        "    result.append(train)\n",
        "    result.append(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shZ8qgEdIxcJ",
        "outputId": "788e0c7f-35d8-4327-93dd-5443a1926e61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "도입기 훈련 데이터 결측치 수 : 0, 도입기 평가 데이터 결측치 수 : 0\n",
            "성장기 훈련 데이터 결측치 수 : 0, 성장기 평가 데이터 결측치 수 : 0\n",
            "성숙기 훈련 데이터 결측치 수 : 0, 성숙기 평가 데이터 결측치 수 : 0\n",
            "쇠퇴기 훈련 데이터 결측치 수 : 0, 쇠퇴기 평가 데이터 결측치 수 : 0\n"
          ]
        }
      ],
      "source": [
        "#위에서 0비율이 높으면서 주식 관련 컬럼 삭제 했음 행 단위로 결측치 제거\n",
        "train_도입.dropna(axis=0,how='any',inplace=True)\n",
        "train_성장.dropna(axis=0,how='any',inplace=True)\n",
        "train_성숙.dropna(axis=0,how='any',inplace=True)\n",
        "train_쇠퇴.dropna(axis=0,how='any',inplace=True)\n",
        "test_도입.dropna(axis=0,how='any',inplace=True)\n",
        "test_성장.dropna(axis=0,how='any',inplace=True)\n",
        "test_성숙.dropna(axis=0,how='any',inplace=True)\n",
        "test_쇠퇴.dropna(axis=0,how='any',inplace=True)\n",
        "print(f\"도입기 훈련 데이터 결측치 수 : {train_도입[numeric_cols1].isna().sum().sum()}, 도입기 평가 데이터 결측치 수 : {test_도입[numeric_cols1].isna().sum().sum()}\")\n",
        "print(f\"성장기 훈련 데이터 결측치 수 : {train_성장[numeric_cols2].isna().sum().sum()}, 성장기 평가 데이터 결측치 수 : {test_성장[numeric_cols2].isna().sum().sum()}\")\n",
        "print(f\"성숙기 훈련 데이터 결측치 수 : {train_성숙[numeric_cols3].isna().sum().sum()}, 성숙기 평가 데이터 결측치 수 : {test_성숙[numeric_cols3].isna().sum().sum()}\")\n",
        "print(f\"쇠퇴기 훈련 데이터 결측치 수 : {train_쇠퇴[numeric_cols4].isna().sum().sum()}, 쇠퇴기 평가 데이터 결측치 수 : {test_쇠퇴[numeric_cols4].isna().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ywYQNSdK7g4"
      },
      "outputs": [],
      "source": [
        "# 기업규모명 삭제(0이 대부분이여서 제거함)\n",
        "train_도입.drop(['대표이사변경여부','상장폐지일'],axis=1,inplace=True)\n",
        "train_성장.drop(['대표이사변경여부','상장폐지일'],axis=1,inplace=True)\n",
        "train_성숙.drop(['대표이사변경여부','상장폐지일'],axis=1,inplace=True)\n",
        "train_쇠퇴.drop(['대표이사변경여부','상장폐지일'],axis=1,inplace=True)\n",
        "test_도입.drop(['대표이사변경여부','상장폐지일'],axis=1,inplace=True)\n",
        "test_성장.drop(['대표이사변경여부','상장폐지일'],axis=1,inplace=True)\n",
        "test_성숙.drop(['대표이사변경여부','상장폐지일'],axis=1,inplace=True)\n",
        "test_쇠퇴.drop(['대표이사변경여부','상장폐지일'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XByLfKdaMgJ2",
        "outputId": "9dcea6f8-ade6-4cca-85ce-c07d60dda262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "도입기 훈련 데이터 결측치 수 : 0, 도입기 평가 데이터 결측치 수 : 0\n",
            "성장기 훈련 데이터 결측치 수 : 0, 성장기 평가 데이터 결측치 수 : 0\n",
            "성숙기 훈련 데이터 결측치 수 : 0, 성숙기 평가 데이터 결측치 수 : 0\n",
            "쇠퇴기 훈련 데이터 결측치 수 : 0, 쇠퇴기 평가 데이터 결측치 수 : 0\n"
          ]
        }
      ],
      "source": [
        "object_cols1 = train_도입.select_dtypes('object').columns\n",
        "object_cols2 = train_성장.select_dtypes('object').columns\n",
        "object_cols3 = train_성숙.select_dtypes('object').columns\n",
        "object_cols4 = train_쇠퇴.select_dtypes('object').columns\n",
        "print(f\"도입기 훈련 데이터 결측치 수 : {train_도입[object_cols1].isna().sum().sum()}, 도입기 평가 데이터 결측치 수 : {test_도입[object_cols1].isna().sum().sum()}\")\n",
        "print(f\"성장기 훈련 데이터 결측치 수 : {train_성장[object_cols2].isna().sum().sum()}, 성장기 평가 데이터 결측치 수 : {test_성장[object_cols2].isna().sum().sum()}\")\n",
        "print(f\"성숙기 훈련 데이터 결측치 수 : {train_성숙[object_cols3].isna().sum().sum()}, 성숙기 평가 데이터 결측치 수 : {test_성숙[object_cols3].isna().sum().sum()}\")\n",
        "print(f\"쇠퇴기 훈련 데이터 결측치 수 : {train_쇠퇴[object_cols4].isna().sum().sum()}, 쇠퇴기 평가 데이터 결측치 수 : {test_쇠퇴[object_cols4].isna().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C0va2TWRLur"
      },
      "outputs": [],
      "source": [
        "# 파일 보내기\n",
        "train_도입.to_csv('도입기_train.csv',index=False)\n",
        "train_성장.to_csv('성장기_train.csv',index=False)\n",
        "train_성숙.to_csv('성숙기_train.csv',index=False)\n",
        "train_쇠퇴.to_csv('쇠퇴기_train.csv',index=False)\n",
        "test_도입.to_csv('도입기_test.csv',index=False)\n",
        "test_성장.to_csv('성장기_test.csv',index=False)\n",
        "test_성숙.to_csv('성숙기_test.csv',index=False)\n",
        "test_쇠퇴.to_csv('쇠퇴기_test.csv',index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOto/tUPb6EXypTBCbV09pH",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
