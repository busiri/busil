{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/busiri/busil/blob/main/5%EB%8B%A8%EA%B3%84_(%EB%AA%A8%EB%8D%B8%EB%A7%81).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f9217adb",
      "metadata": {
        "id": "f9217adb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "91b89294-0ab1-4bef-9c34-a9b309fd3a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 10.3 MB of archives.\n",
            "After this operation, 34.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n",
            "Fetched 10.3 MB in 2s (6,158 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 126281 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "/usr/share/fonts/truetype/nanum/NanumSquareB.ttf\n",
            "/usr/share/fonts/truetype/nanum/NanumMyeongjoBold.ttf\n",
            "/usr/share/fonts/truetype/nanum/NanumGothicCodingBold.ttf\n",
            "/usr/share/fonts/truetype/nanum/NanumSquareR.ttf\n",
            "/usr/share/fonts/truetype/nanum/NanumSquareRoundR.ttf\n",
            "/usr/share/fonts/truetype/nanum/NanumBarunGothicBold.ttf\n",
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf\n",
            "/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf\n",
            "/usr/share/fonts/truetype/nanum/NanumMyeongjo.ttf\n",
            "/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf\n",
            "/usr/share/fonts/truetype/nanum/NanumSquareRoundB.ttf\n",
            "/usr/share/fonts/truetype/nanum/NanumGothicCoding.ttf\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.preprocessing import RobustScaler, KBinsDiscretizer, PolynomialFeatures\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from imblearn.pipeline       import Pipeline\n",
        "from imblearn.ensemble       import BalancedRandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict,train_test_split,cross_val_score\n",
        "from sklearn.metrics         import (\n",
        "    classification_report,\n",
        "    average_precision_score,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    f1_score\n",
        ")\n",
        "import platform\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from joblib import parallel_backend\n",
        "\n",
        "\n",
        "# 한글 폰트 설정 (예: 맑은 고딕)\n",
        "# 폰트 설치\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "\n",
        "# 설치된 Nanum 폰트 경로 확인\n",
        "font_dirs = ['/usr/share/fonts/truetype/nanum/']\n",
        "font_files = fm.findSystemFonts(fontpaths=font_dirs)\n",
        "\n",
        "# 폰트 매니저에 폰트 추가\n",
        "for font_file in font_files:\n",
        "    fm.fontManager.addfont(font_file)\n",
        "\n",
        "for f in fm.findSystemFonts(fontpaths=None, fontext='ttf'):\n",
        "    if 'Nanum' in f:\n",
        "        print(f)\n",
        "# 폰트 이름 확인\n",
        "nanum_font = fm.FontProperties(fname=font_files[0]).get_name()\n",
        "\n",
        "# 폰트 설정\n",
        "plt.rcParams['font.family'] = nanum_font\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "mpl.rcParams['font.family'] = nanum_font\n",
        "mpl.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "font_prop = fm.FontProperties(fname=font_path)\n",
        "\n",
        "plt.rcParams['font.family'] = font_prop.get_name()\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 불러오기"
      ],
      "metadata": {
        "id": "FKMh0YGhjKWO"
      },
      "id": "FKMh0YGhjKWO"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "69c3e179",
      "metadata": {
        "id": "69c3e179"
      },
      "outputs": [],
      "source": [
        "#도입기\n",
        "train_df = pd.read_csv(\"/content/도입_final_파생추가.csv\")\n",
        "train_df.drop('회사명',axis=1,inplace=True)\n",
        "test_df = pd.read_csv(\"/content/도입기_test.csv\")\n",
        "test_df = test_df[train_df.columns]\n",
        "\n",
        "# #성장기\n",
        "# train_df = pd.read_csv(\"/content/성장_final_파생추가.csv\")\n",
        "# train_df.drop('회사명',axis=1,inplace=True)\n",
        "# test_df = pd.read_csv(\"/content/성장기_test.csv\")\n",
        "# test_df = test_df[train_df.columns]\n",
        "\n",
        "# #성숙기\n",
        "# train_df = pd.read_csv(\"/content/성숙_final_파생추가.csv\")\n",
        "# train_df.drop('회사명',axis=1,inplace=True)\n",
        "# test_df = pd.read_csv(\"/content/성숙기_test.csv\")\n",
        "# test_df = test_df[train_df.columns]\n",
        "\n",
        "# #쇠퇴기\n",
        "# train_df = pd.read_csv(\"/content/쇠퇴_final_파생추가.csv\")\n",
        "# train_df.drop('회사명',axis=1,inplace=True)\n",
        "# test_df = pd.read_csv(\"/content/쇠퇴기_test.csv\")\n",
        "# test_df = test_df[train_df.columns]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기업규모명, 통계청 한국표준산업분류 11차(대분류) 라벨인코딩\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder1 = LabelEncoder()\n",
        "encoder2 = LabelEncoder()\n",
        "train_df['기업규모명'] = encoder1.fit_transform(train_df['기업규모명'])\n",
        "test_df['기업규모명'] = encoder1.transform(test_df['기업규모명'])\n",
        "\n",
        "train_df['통계청 한국표준산업분류 11차(대분류)'] = encoder2.fit_transform(train_df['통계청 한국표준산업분류 11차(대분류)'])\n",
        "test_df['통계청 한국표준산업분류 11차(대분류)'] = encoder2.transform(test_df['통계청 한국표준산업분류 11차(대분류)'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "collapsed": true,
        "id": "SLz2Od1YjSZC",
        "outputId": "c280a7f7-b5d8-4383-f4c8-a7b4ae2557a3"
      },
      "id": "SLz2Od1YjSZC",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              회사명 기업규모명    통계청 한국표준산업분류 11차(대분류)\n",
              "0      제일스텐철강주식회사  중소기업                 도매 및 소매업\n",
              "1          엘앤케이씨티  중소기업                 운수 및 창고업\n",
              "2      (주)나비디벨롭먼트  중소기업                      건설업\n",
              "3         주식회사엔이티  중소기업    전기, 가스, 증기 및 공기조절 공급업\n",
              "4        애플디앤씨(주)  중소기업                     부동산업\n",
              "...           ...   ...                      ...\n",
              "7871  주식회사강림C.S.P  중견기업                      제조업\n",
              "7872     (주)안산이에스  중소기업  수도, 하수 및 폐기물 처리, 원료 재생업\n",
              "7873    주식회사남경플러스  중소기업                     부동산업\n",
              "7874   주식회사보령파트너스  중소기업         전문, 과학 및 기술 서비스업\n",
              "7875          NaN   NaN                      NaN\n",
              "\n",
              "[7876 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9ef26eb-f6e8-4ec3-bbc0-69a9eb97aa5a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>회사명</th>\n",
              "      <th>기업규모명</th>\n",
              "      <th>통계청 한국표준산업분류 11차(대분류)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>제일스텐철강주식회사</td>\n",
              "      <td>중소기업</td>\n",
              "      <td>도매 및 소매업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>엘앤케이씨티</td>\n",
              "      <td>중소기업</td>\n",
              "      <td>운수 및 창고업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(주)나비디벨롭먼트</td>\n",
              "      <td>중소기업</td>\n",
              "      <td>건설업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>주식회사엔이티</td>\n",
              "      <td>중소기업</td>\n",
              "      <td>전기, 가스, 증기 및 공기조절 공급업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>애플디앤씨(주)</td>\n",
              "      <td>중소기업</td>\n",
              "      <td>부동산업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7871</th>\n",
              "      <td>주식회사강림C.S.P</td>\n",
              "      <td>중견기업</td>\n",
              "      <td>제조업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7872</th>\n",
              "      <td>(주)안산이에스</td>\n",
              "      <td>중소기업</td>\n",
              "      <td>수도, 하수 및 폐기물 처리, 원료 재생업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7873</th>\n",
              "      <td>주식회사남경플러스</td>\n",
              "      <td>중소기업</td>\n",
              "      <td>부동산업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7874</th>\n",
              "      <td>주식회사보령파트너스</td>\n",
              "      <td>중소기업</td>\n",
              "      <td>전문, 과학 및 기술 서비스업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7875</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7876 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9ef26eb-f6e8-4ec3-bbc0-69a9eb97aa5a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c9ef26eb-f6e8-4ec3-bbc0-69a9eb97aa5a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c9ef26eb-f6e8-4ec3-bbc0-69a9eb97aa5a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1cab68a2-486b-4118-8e97-7b4a1e471458\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1cab68a2-486b-4118-8e97-7b4a1e471458')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1cab68a2-486b-4118-8e97-7b4a1e471458 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 7876,\n  \"fields\": [\n    {\n      \"column\": \"\\ud68c\\uc0ac\\uba85\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6399,\n        \"samples\": [\n          \"(\\uc8fc)\\uc0dd\\ud544\\uccb4\\uc778\",\n          \"\\ud718\\ud2b8\\ub2c8\\uc2a4\\uc11c\\ube44\\uc2a4\\uc778\\ud130\\ub0b4\\uc154\\ub0a0(\\uc8fc)\",\n          \"(\\uc8fc)\\uc740\\uc131\\ubaa9\\uc7ac\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uae30\\uc5c5\\uaddc\\ubaa8\\uba85\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"\\uc911\\uacac\\uae30\\uc5c5\",\n          \"\\uae30\\ud0c0\",\n          \"\\uc911\\uc18c\\uae30\\uc5c5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud1b5\\uacc4\\uccad \\ud55c\\uad6d\\ud45c\\uc900\\uc0b0\\uc5c5\\ubd84\\ub958 11\\ucc28(\\ub300\\ubd84\\ub958)\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"\\ub3c4\\ub9e4 \\ubc0f \\uc18c\\ub9e4\\uc5c5\",\n          \"\\uc6b4\\uc218 \\ubc0f \\ucc3d\\uace0\\uc5c5\",\n          \"\\uc218\\ub3c4, \\ud558\\uc218 \\ubc0f \\ud3d0\\uae30\\ubb3c \\ucc98\\ub9ac, \\uc6d0\\ub8cc \\uc7ac\\uc0dd\\uc5c5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tr, y_train = train_df.drop('부실여부',axis=1), train_df['부실여부']\n",
        "df_te, y_test = test_df.drop('부실여부',axis=1), test_df['부실여부']"
      ],
      "metadata": {
        "id": "Li2yqgUlkK0U"
      },
      "id": "Li2yqgUlkK0U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델링 : 오버샘플링 진행하여 학습"
      ],
      "metadata": {
        "id": "bYiWP_Hlm1h5"
      },
      "id": "bYiWP_Hlm1h5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델1 : Balanced RF"
      ],
      "metadata": {
        "id": "62Iw3R6Rj-w5"
      },
      "id": "62Iw3R6Rj-w5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc6a0ce5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc6a0ce5",
        "outputId": "d8de7b8a-5054-4445-cd3d-aca5a8d2316f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Validation (5-fold) =====\n",
            "PR AUC   : 0.3956\n",
            "Recall   : 0.5905\n",
            "Precision: 0.3560\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9840    0.9594    0.9715     16563\n",
            "           1     0.3560    0.5905    0.4442       630\n",
            "\n",
            "    accuracy                         0.9459     17193\n",
            "   macro avg     0.6700    0.7749    0.7079     17193\n",
            "weighted avg     0.9610    0.9459    0.9522     17193\n",
            "\n",
            "===== Test =====\n",
            "PR AUC   : 0.4164\n",
            "Recall   : 0.6646\n",
            "Precision: 0.3832\n",
            "f1_score: 0.4861\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9868    0.9592    0.9728      4141\n",
            "           1     0.3832    0.6646    0.4861       158\n",
            "\n",
            "    accuracy                         0.9484      4299\n",
            "   macro avg     0.6850    0.8119    0.7295      4299\n",
            "weighted avg     0.9646    0.9484    0.9549      4299\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────────\n",
        "# 1) Balanced RF\n",
        "# ─────────────────────────────────────────────────────────────────\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "SM = BorderlineSMOTE(sampling_strategy=0.3, kind='borderline-1', random_state=42)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 파이프라인 정의:\n",
        "#   1) SMOTE\n",
        "#   2) BalancedRF로 feature_importances_ 학습\n",
        "#   3) BalancedRF로 최종 예측\n",
        "# ------------------------------------------------------------------\n",
        "pipe_brf_top50 = Pipeline([\n",
        "    ('smote',   SM),\n",
        "    ('feat_sel', SelectFromModel(\n",
        "        estimator=BalancedRandomForestClassifier(\n",
        "            n_estimators=100, random_state=42\n",
        "        ),\n",
        "\n",
        "        threshold=-np.inf,\n",
        "        prefit=False\n",
        "    )),\n",
        "    ('clf',     BalancedRandomForestClassifier(\n",
        "        n_estimators=100, random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 평가 함수 (5-fold CV + test)\n",
        "# ------------------------------------------------------------------\n",
        "def evaluate(pipe, X_tr, y_tr, X_te, y_te, thresh=0.5):\n",
        "    # threading 백엔드로 병렬 실행\n",
        "    with parallel_backend('threading', n_jobs=-1):\n",
        "        y_val_proba = cross_val_predict(\n",
        "            pipe, X_tr, y_tr,\n",
        "            cv=cv,\n",
        "            method='predict_proba',\n",
        "            n_jobs=-1\n",
        "        )[:,1]\n",
        "    val_pr  = average_precision_score(y_tr, y_val_proba)\n",
        "    y_val_pred = (y_val_proba >= thresh).astype(int)\n",
        "    val_rec = recall_score(y_tr, y_val_pred)\n",
        "    val_pre = precision_score(y_tr, y_val_pred)\n",
        "\n",
        "    print(\"===== Validation (5-fold) =====\")\n",
        "    print(f\"PR AUC   : {val_pr:.4f}\")\n",
        "    print(f\"Recall   : {val_rec:.4f}\")\n",
        "    print(f\"Precision: {val_pre:.4f}\")\n",
        "    print(classification_report(y_tr, y_val_pred, digits=4))\n",
        "\n",
        "    # 전체 학습 → 테스트\n",
        "    pipe.fit(X_tr, y_tr)\n",
        "    y_test_proba = pipe.predict_proba(X_te)[:,1]\n",
        "    y_test_pred  = (y_test_proba >= thresh).astype(int)\n",
        "    test_pr  = average_precision_score(y_te, y_test_proba)\n",
        "    test_rec = recall_score(y_te, y_test_pred)\n",
        "    test_pre = precision_score(y_te, y_test_pred)\n",
        "    test_f1 = f1_score(y_te,y_test_pred)\n",
        "\n",
        "    print(\"===== Test =====\")\n",
        "    print(f\"PR AUC   : {test_pr:.4f}\")\n",
        "    print(f\"Recall   : {test_rec:.4f}\")\n",
        "    print(f\"Precision: {test_pre:.4f}\")\n",
        "    print(f\"f1_score: {test_f1:.4f}\")\n",
        "    print(classification_report(y_te, y_test_pred, digits=4))\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 실행\n",
        "# ------------------------------------------------------------------\n",
        "evaluate(pipe_brf_top50, df_tr, y_train, df_te, y_test, thresh=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델2 : 로지스틱 회귀"
      ],
      "metadata": {
        "id": "19CmIE7CmjV0"
      },
      "id": "19CmIE7CmjV0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3025aeea",
      "metadata": {
        "id": "3025aeea",
        "outputId": "04319d7b-d2ae-4acb-c8b2-89a815741860"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Logistic Regression ###\n",
            "===== Validation (5-fold) =====\n",
            "PR AUC   : 0.3128\n",
            "Recall   : 0.6016\n",
            "Precision: 0.3044\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9843    0.9477    0.9656     16563\n",
            "           1     0.3044    0.6016    0.4043       630\n",
            "\n",
            "    accuracy                         0.9350     17193\n",
            "   macro avg     0.6443    0.7747    0.6850     17193\n",
            "weighted avg     0.9593    0.9350    0.9451     17193\n",
            "\n",
            "===== Test =====\n",
            "PR AUC   : 0.3495\n",
            "Recall   : 0.6392\n",
            "Precision: 0.3217\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9857    0.9486    0.9668      4141\n",
            "           1     0.3217    0.6392    0.4280       158\n",
            "\n",
            "    accuracy                         0.9372      4299\n",
            "   macro avg     0.6537    0.7939    0.6974      4299\n",
            "weighted avg     0.9613    0.9372    0.9470      4299\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ─────────────────────────────────────────────────────────────────\n",
        "# 2) Logistic Regression\n",
        "# ─────────────────────────────────────────────────────────────────\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "pipe_lr = Pipeline([\n",
        "    ('smote',   SM),\n",
        "    ('feat_sel', SelectFromModel(\n",
        "        estimator=BalancedRandomForestClassifier(n_estimators=100, random_state=42),\n",
        "         threshold=-np.inf, prefit=False\n",
        "    )),\n",
        "    ('clf',     LogisticRegression(solver='liblinear', random_state=42))\n",
        "])\n",
        "\n",
        "print(\"### Logistic Regression ###\")\n",
        "evaluate(pipe_lr, df_tr, y_train, df_te, y_test, thresh=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델3 : LightGBM"
      ],
      "metadata": {
        "id": "nflvOIrqmoLb"
      },
      "id": "nflvOIrqmoLb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43ddca2b",
      "metadata": {
        "id": "43ddca2b",
        "outputId": "9488f810-15d0-4337-b329-b4d42c0bf349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 3975, number of negative: 13250\n",
            "[LightGBM] [Info] Number of positive: 3975, number of negative: 13250\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009017 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 34720\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022904 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Number of data points in the train set: 17225, number of used features: 137\n",
            "[LightGBM] [Info] Total Bins 34724\n",
            "[LightGBM] [Info] Number of data points in the train set: 17225, number of used features: 137\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 3975, number of negative: 13250\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007914 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 34713\n",
            "[LightGBM] [Info] Number of data points in the train set: 17225, number of used features: 137\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 3975, number of negative: 13251\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006015 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 34727\n",
            "[LightGBM] [Info] Number of data points in the train set: 17226, number of used features: 137\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Info] Number of positive: 3975, number of negative: 13251\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004430 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 34720\n",
            "[LightGBM] [Info] Number of data points in the train set: 17226, number of used features: 137\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "===== Validation (5-fold) =====\n",
            "PR AUC   : 0.4599\n",
            "Recall   : 0.6444\n",
            "Precision: 0.3648\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9861    0.9573    0.9715     16563\n",
            "           1     0.3648    0.6444    0.4659       630\n",
            "\n",
            "    accuracy                         0.9459     17193\n",
            "   macro avg     0.6754    0.8009    0.7187     17193\n",
            "weighted avg     0.9633    0.9459    0.9530     17193\n",
            "\n",
            "[LightGBM] [Info] Number of positive: 4968, number of negative: 16563\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004331 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 34744\n",
            "[LightGBM] [Info] Number of data points in the train set: 21531, number of used features: 137\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n",
            "===== Test =====\n",
            "PR AUC   : 0.4722\n",
            "Recall   : 0.7342\n",
            "Precision: 0.3828\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9895    0.9548    0.9719      4141\n",
            "           1     0.3828    0.7342    0.5033       158\n",
            "\n",
            "    accuracy                         0.9467      4299\n",
            "   macro avg     0.6862    0.8445    0.7376      4299\n",
            "weighted avg     0.9672    0.9467    0.9546      4299\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    average_precision_score,\n",
        "    recall_score,\n",
        "    precision_score\n",
        ")\n",
        "from joblib import parallel_backend\n",
        "\n",
        "# 준비된 데이터: df_tr, df_te, y_train, y_test\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "SM = BorderlineSMOTE(sampling_strategy=0.3, kind='borderline-1', random_state=42)\n",
        "\n",
        "# LGBM 파이프라인 정의\n",
        "pipe_lgbm_top50 = Pipeline([\n",
        "    ('smote', SM),\n",
        "    ('feat_sel', SelectFromModel(\n",
        "        estimator=BalancedRandomForestClassifier(\n",
        "            n_estimators=100, random_state=42\n",
        "        ),\n",
        "\n",
        "        threshold=-np.inf,\n",
        "        prefit=False\n",
        "    )),\n",
        "    ('clf', lgb.LGBMClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.05,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 평가 함수 그대로 사용\n",
        "def evaluate(pipe, X_tr, y_tr, X_te, y_te, thresh=0.5):\n",
        "    with parallel_backend('threading', n_jobs=-1):\n",
        "        y_val_proba = cross_val_predict(\n",
        "            pipe, X_tr, y_tr,\n",
        "            cv=cv,\n",
        "            method='predict_proba',\n",
        "            n_jobs=-1\n",
        "        )[:, 1]\n",
        "    val_pr  = average_precision_score(y_tr, y_val_proba)\n",
        "    y_val_pred = (y_val_proba >= thresh).astype(int)\n",
        "    val_rec = recall_score(y_tr, y_val_pred)\n",
        "    val_pre = precision_score(y_tr, y_val_pred)\n",
        "\n",
        "    print(\"===== Validation (5-fold) =====\")\n",
        "    print(f\"PR AUC   : {val_pr:.4f}\")\n",
        "    print(f\"Recall   : {val_rec:.4f}\")\n",
        "    print(f\"Precision: {val_pre:.4f}\")\n",
        "    print(classification_report(y_tr, y_val_pred, digits=4))\n",
        "\n",
        "    pipe.fit(X_tr, y_tr)\n",
        "    y_test_proba = pipe.predict_proba(X_te)[:, 1]\n",
        "    y_test_pred  = (y_test_proba >= thresh).astype(int)\n",
        "    test_pr  = average_precision_score(y_te, y_test_proba)\n",
        "    test_rec = recall_score(y_te, y_test_pred)\n",
        "    test_pre = precision_score(y_te, y_test_pred)\n",
        "\n",
        "    print(\"===== Test =====\")\n",
        "    print(f\"PR AUC   : {test_pr:.4f}\")\n",
        "    print(f\"Recall   : {test_rec:.4f}\")\n",
        "    print(f\"Precision: {test_pre:.4f}\")\n",
        "    print(classification_report(y_te, y_test_pred, digits=4))\n",
        "\n",
        "# 실행\n",
        "evaluate(pipe_lgbm_top50, df_tr, y_train, df_te, y_test, thresh=0.5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델4 : TabNet"
      ],
      "metadata": {
        "id": "DzAF3gOznQiJ"
      },
      "id": "DzAF3gOznQiJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "990bef22",
      "metadata": {
        "id": "990bef22",
        "outputId": "1b13c704-05a5-442d-b18b-c95addf5322d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### TabNet ###\n",
            "epoch 0  | loss: 0.77415 | val_0_auc: 0.70003 |  0:00:03s\n",
            "epoch 0  | loss: 0.7547  | val_0_auc: 0.72136 |  0:00:03s\n",
            "epoch 0  | loss: 0.81041 | val_0_auc: 0.66594 |  0:00:03s\n",
            "epoch 0  | loss: 0.78844 | val_0_auc: 0.71084 |  0:00:03s\n",
            "epoch 0  | loss: 0.76948 | val_0_auc: 0.68426 |  0:00:03s\n",
            "epoch 1  | loss: 0.52214 | val_0_auc: 0.80032 |  0:00:06s\n",
            "epoch 1  | loss: 0.51072 | val_0_auc: 0.81617 |  0:00:06s\n",
            "epoch 1  | loss: 0.52316 | val_0_auc: 0.84622 |  0:00:06s\n",
            "epoch 1  | loss: 0.55084 | val_0_auc: 0.76153 |  0:00:06s\n",
            "epoch 1  | loss: 0.52834 | val_0_auc: 0.81366 |  0:00:06s\n",
            "epoch 2  | loss: 0.43461 | val_0_auc: 0.87031 |  0:00:09s\n",
            "epoch 2  | loss: 0.43574 | val_0_auc: 0.86849 |  0:00:09s\n",
            "epoch 2  | loss: 0.43571 | val_0_auc: 0.87291 |  0:00:10s\n",
            "epoch 2  | loss: 0.41208 | val_0_auc: 0.88471 |  0:00:10s\n",
            "epoch 2  | loss: 0.47274 | val_0_auc: 0.85918 |  0:00:10s\n",
            "epoch 3  | loss: 0.38561 | val_0_auc: 0.88381 |  0:00:13s\n",
            "epoch 3  | loss: 0.37301 | val_0_auc: 0.90743 |  0:00:13s\n",
            "epoch 3  | loss: 0.37576 | val_0_auc: 0.89114 |  0:00:13s\n",
            "epoch 3  | loss: 0.39657 | val_0_auc: 0.88437 |  0:00:13s\n",
            "epoch 3  | loss: 0.34391 | val_0_auc: 0.92571 |  0:00:13s\n",
            "epoch 4  | loss: 0.35351 | val_0_auc: 0.90372 |  0:00:16s\n",
            "epoch 4  | loss: 0.33037 | val_0_auc: 0.93013 |  0:00:16s\n",
            "epoch 4  | loss: 0.35273 | val_0_auc: 0.90068 |  0:00:16s\n",
            "epoch 4  | loss: 0.35499 | val_0_auc: 0.91635 |  0:00:16s\n",
            "epoch 4  | loss: 0.30637 | val_0_auc: 0.92172 |  0:00:16s\n",
            "epoch 5  | loss: 0.33257 | val_0_auc: 0.9343  |  0:00:19s\n",
            "epoch 5  | loss: 0.28618 | val_0_auc: 0.93999 |  0:00:19s\n",
            "epoch 5  | loss: 0.33791 | val_0_auc: 0.91378 |  0:00:19s\n",
            "epoch 5  | loss: 0.31296 | val_0_auc: 0.93515 |  0:00:19s\n",
            "epoch 5  | loss: 0.28613 | val_0_auc: 0.94494 |  0:00:19s\n",
            "epoch 6  | loss: 0.29239 | val_0_auc: 0.94831 |  0:00:21s\n",
            "epoch 6  | loss: 0.27116 | val_0_auc: 0.9488  |  0:00:22s\n",
            "epoch 6  | loss: 0.31746 | val_0_auc: 0.92752 |  0:00:22s\n",
            "epoch 6  | loss: 0.27835 | val_0_auc: 0.94554 |  0:00:22s\n",
            "epoch 6  | loss: 0.2455  | val_0_auc: 0.95838 |  0:00:22s\n",
            "epoch 7  | loss: 0.26518 | val_0_auc: 0.95261 |  0:00:25s\n",
            "epoch 7  | loss: 0.25151 | val_0_auc: 0.95736 |  0:00:25s\n",
            "epoch 7  | loss: 0.2962  | val_0_auc: 0.93792 |  0:00:25s\n",
            "epoch 7  | loss: 0.23074 | val_0_auc: 0.96207 |  0:00:25s\n",
            "epoch 7  | loss: 0.26102 | val_0_auc: 0.94557 |  0:00:25s\n",
            "epoch 8  | loss: 0.25201 | val_0_auc: 0.94839 |  0:00:27s\n",
            "epoch 8  | loss: 0.22942 | val_0_auc: 0.95883 |  0:00:27s\n",
            "epoch 8  | loss: 0.28006 | val_0_auc: 0.94632 |  0:00:28s\n",
            "epoch 8  | loss: 0.25087 | val_0_auc: 0.95309 |  0:00:28s\n",
            "epoch 8  | loss: 0.21753 | val_0_auc: 0.96469 |  0:00:28s\n",
            "epoch 9  | loss: 0.23828 | val_0_auc: 0.95793 |  0:00:30s\n",
            "epoch 9  | loss: 0.22882 | val_0_auc: 0.9638  |  0:00:30s\n",
            "epoch 9  | loss: 0.26566 | val_0_auc: 0.94992 |  0:00:31s\n",
            "epoch 9  | loss: 0.21643 | val_0_auc: 0.96204 |  0:00:31s\n",
            "epoch 9  | loss: 0.23595 | val_0_auc: 0.95637 |  0:00:31s\n",
            "epoch 10 | loss: 0.23301 | val_0_auc: 0.96139 |  0:00:33s\n",
            "epoch 10 | loss: 0.22608 | val_0_auc: 0.9601  |  0:00:33s\n",
            "epoch 10 | loss: 0.24253 | val_0_auc: 0.95474 |  0:00:33s\n",
            "epoch 10 | loss: 0.21123 | val_0_auc: 0.96706 |  0:00:34s\n",
            "epoch 10 | loss: 0.2316  | val_0_auc: 0.95719 |  0:00:34s\n",
            "epoch 11 | loss: 0.22502 | val_0_auc: 0.96232 |  0:00:36s\n",
            "epoch 11 | loss: 0.21367 | val_0_auc: 0.9661  |  0:00:36s\n",
            "epoch 11 | loss: 0.23398 | val_0_auc: 0.95987 |  0:00:36s\n",
            "epoch 11 | loss: 0.19985 | val_0_auc: 0.97026 |  0:00:36s\n",
            "epoch 11 | loss: 0.22567 | val_0_auc: 0.96201 |  0:00:36s\n",
            "epoch 12 | loss: 0.21919 | val_0_auc: 0.96683 |  0:00:39s\n",
            "epoch 12 | loss: 0.20876 | val_0_auc: 0.96628 |  0:00:39s\n",
            "epoch 12 | loss: 0.22231 | val_0_auc: 0.96148 |  0:00:39s\n",
            "epoch 12 | loss: 0.19334 | val_0_auc: 0.97073 |  0:00:39s\n",
            "epoch 12 | loss: 0.21631 | val_0_auc: 0.96465 |  0:00:39s\n",
            "epoch 13 | loss: 0.20824 | val_0_auc: 0.9704  |  0:00:42s\n",
            "epoch 13 | loss: 0.20126 | val_0_auc: 0.96786 |  0:00:42s\n",
            "epoch 13 | loss: 0.2189  | val_0_auc: 0.96652 |  0:00:42s\n",
            "epoch 13 | loss: 0.20896 | val_0_auc: 0.96644 |  0:00:43s\n",
            "epoch 13 | loss: 0.19424 | val_0_auc: 0.97184 |  0:00:43s\n",
            "epoch 14 | loss: 0.20097 | val_0_auc: 0.96823 |  0:00:45s\n",
            "epoch 14 | loss: 0.19506 | val_0_auc: 0.9714  |  0:00:45s\n",
            "epoch 14 | loss: 0.21472 | val_0_auc: 0.96765 |  0:00:45s\n",
            "epoch 14 | loss: 0.20554 | val_0_auc: 0.9691  |  0:00:46s\n",
            "epoch 14 | loss: 0.18558 | val_0_auc: 0.97434 |  0:00:46s\n",
            "epoch 15 | loss: 0.20155 | val_0_auc: 0.97016 |  0:00:48s\n",
            "epoch 15 | loss: 0.18971 | val_0_auc: 0.96968 |  0:00:48s\n",
            "epoch 15 | loss: 0.21002 | val_0_auc: 0.96833 |  0:00:48s\n",
            "epoch 15 | loss: 0.18082 | val_0_auc: 0.97675 |  0:00:48s\n",
            "epoch 15 | loss: 0.19424 | val_0_auc: 0.97075 |  0:00:48s\n",
            "epoch 16 | loss: 0.19756 | val_0_auc: 0.97042 |  0:00:51s\n",
            "epoch 16 | loss: 0.19535 | val_0_auc: 0.97137 |  0:00:51s\n",
            "epoch 16 | loss: 0.20248 | val_0_auc: 0.96874 |  0:00:51s\n",
            "epoch 16 | loss: 0.1943  | val_0_auc: 0.97191 |  0:00:51s\n",
            "epoch 16 | loss: 0.18064 | val_0_auc: 0.97463 |  0:00:51s\n",
            "epoch 17 | loss: 0.19526 | val_0_auc: 0.97388 |  0:00:54s\n",
            "epoch 17 | loss: 0.18787 | val_0_auc: 0.97275 |  0:00:54s\n",
            "epoch 17 | loss: 0.19538 | val_0_auc: 0.9717  |  0:00:54s\n",
            "epoch 17 | loss: 0.18556 | val_0_auc: 0.97323 |  0:00:54s\n",
            "epoch 17 | loss: 0.17868 | val_0_auc: 0.97715 |  0:00:54s\n",
            "epoch 18 | loss: 0.18683 | val_0_auc: 0.97592 |  0:00:57s\n",
            "epoch 18 | loss: 0.18475 | val_0_auc: 0.97711 |  0:00:57s\n",
            "epoch 18 | loss: 0.1861  | val_0_auc: 0.9757  |  0:00:57s\n",
            "epoch 18 | loss: 0.16916 | val_0_auc: 0.97832 |  0:00:57s\n",
            "epoch 18 | loss: 0.18506 | val_0_auc: 0.9747  |  0:00:57s\n",
            "epoch 19 | loss: 0.1844  | val_0_auc: 0.97543 |  0:01:00s\n",
            "epoch 19 | loss: 0.17328 | val_0_auc: 0.97818 |  0:01:00s\n",
            "epoch 19 | loss: 0.17994 | val_0_auc: 0.9772  |  0:01:00s\n",
            "epoch 19 | loss: 0.16745 | val_0_auc: 0.97998 |  0:01:00s\n",
            "epoch 19 | loss: 0.17996 | val_0_auc: 0.97581 |  0:01:00s\n",
            "epoch 20 | loss: 0.17919 | val_0_auc: 0.97565 |  0:01:03s\n",
            "epoch 20 | loss: 0.17602 | val_0_auc: 0.97887 |  0:01:03s\n",
            "epoch 20 | loss: 0.17716 | val_0_auc: 0.97548 |  0:01:03s\n",
            "epoch 20 | loss: 0.17577 | val_0_auc: 0.97734 |  0:01:03s\n",
            "epoch 20 | loss: 0.16195 | val_0_auc: 0.98241 |  0:01:03s\n",
            "epoch 21 | loss: 0.17816 | val_0_auc: 0.9778  |  0:01:05s\n",
            "epoch 21 | loss: 0.16893 | val_0_auc: 0.9804  |  0:01:06s\n",
            "epoch 21 | loss: 0.17711 | val_0_auc: 0.97803 |  0:01:06s\n",
            "epoch 21 | loss: 0.15539 | val_0_auc: 0.98335 |  0:01:06s\n",
            "epoch 21 | loss: 0.17301 | val_0_auc: 0.9812  |  0:01:06s\n",
            "epoch 22 | loss: 0.17955 | val_0_auc: 0.97782 |  0:01:08s\n",
            "epoch 22 | loss: 0.16078 | val_0_auc: 0.98257 |  0:01:09s\n",
            "epoch 22 | loss: 0.17732 | val_0_auc: 0.97866 |  0:01:09s\n",
            "epoch 22 | loss: 0.15378 | val_0_auc: 0.98377 |  0:01:09s\n",
            "epoch 22 | loss: 0.16799 | val_0_auc: 0.98094 |  0:01:09s\n",
            "epoch 23 | loss: 0.17567 | val_0_auc: 0.97913 |  0:01:11s\n",
            "epoch 23 | loss: 0.15213 | val_0_auc: 0.98485 |  0:01:11s\n",
            "epoch 23 | loss: 0.16479 | val_0_auc: 0.97988 |  0:01:12s\n",
            "epoch 23 | loss: 0.1478  | val_0_auc: 0.9845  |  0:01:12s\n",
            "epoch 23 | loss: 0.16123 | val_0_auc: 0.98274 |  0:01:12s\n",
            "epoch 24 | loss: 0.17568 | val_0_auc: 0.97846 |  0:01:14s\n",
            "epoch 24 | loss: 0.1438  | val_0_auc: 0.98641 |  0:01:14s\n",
            "epoch 24 | loss: 0.16531 | val_0_auc: 0.98032 |  0:01:15s\n",
            "epoch 24 | loss: 0.13809 | val_0_auc: 0.98671 |  0:01:15s\n",
            "epoch 24 | loss: 0.15607 | val_0_auc: 0.98328 |  0:01:15s\n",
            "epoch 25 | loss: 0.16999 | val_0_auc: 0.97732 |  0:01:17s\n",
            "epoch 25 | loss: 0.13649 | val_0_auc: 0.98891 |  0:01:17s\n",
            "epoch 25 | loss: 0.17217 | val_0_auc: 0.9814  |  0:01:18s\n",
            "epoch 25 | loss: 0.13485 | val_0_auc: 0.98769 |  0:01:18s\n",
            "epoch 25 | loss: 0.14843 | val_0_auc: 0.98457 |  0:01:18s\n",
            "epoch 26 | loss: 0.17368 | val_0_auc: 0.97958 |  0:01:20s\n",
            "epoch 26 | loss: 0.12954 | val_0_auc: 0.98964 |  0:01:21s\n",
            "epoch 26 | loss: 0.15826 | val_0_auc: 0.98376 |  0:01:21s\n",
            "epoch 26 | loss: 0.13522 | val_0_auc: 0.98665 |  0:01:21s\n",
            "epoch 26 | loss: 0.1487  | val_0_auc: 0.98481 |  0:01:21s\n",
            "epoch 27 | loss: 0.16691 | val_0_auc: 0.97908 |  0:01:23s\n",
            "epoch 27 | loss: 0.12353 | val_0_auc: 0.99066 |  0:01:23s\n",
            "epoch 27 | loss: 0.15222 | val_0_auc: 0.98406 |  0:01:24s\n",
            "epoch 27 | loss: 0.13126 | val_0_auc: 0.98856 |  0:01:24s\n",
            "epoch 27 | loss: 0.15536 | val_0_auc: 0.98357 |  0:01:24s\n",
            "epoch 28 | loss: 0.16976 | val_0_auc: 0.97917 |  0:01:26s\n",
            "epoch 28 | loss: 0.12746 | val_0_auc: 0.98958 |  0:01:26s\n",
            "epoch 28 | loss: 0.15167 | val_0_auc: 0.98537 |  0:01:27s\n",
            "epoch 28 | loss: 0.13192 | val_0_auc: 0.98947 |  0:01:27s\n",
            "epoch 28 | loss: 0.15107 | val_0_auc: 0.98483 |  0:01:27s\n",
            "epoch 29 | loss: 0.16218 | val_0_auc: 0.98178 |  0:01:29s\n",
            "epoch 29 | loss: 0.123   | val_0_auc: 0.99196 |  0:01:29s\n",
            "epoch 29 | loss: 0.13885 | val_0_auc: 0.98803 |  0:01:30s\n",
            "epoch 29 | loss: 0.12522 | val_0_auc: 0.9897  |  0:01:30s\n",
            "epoch 29 | loss: 0.1488  | val_0_auc: 0.98592 |  0:01:30s\n",
            "epoch 30 | loss: 0.15961 | val_0_auc: 0.9829  |  0:01:32s\n",
            "epoch 30 | loss: 0.11091 | val_0_auc: 0.99328 |  0:01:33s\n",
            "epoch 30 | loss: 0.13411 | val_0_auc: 0.98959 |  0:01:33s\n",
            "epoch 30 | loss: 0.12478 | val_0_auc: 0.99082 |  0:01:33s\n",
            "epoch 30 | loss: 0.14308 | val_0_auc: 0.98729 |  0:01:34s\n",
            "epoch 31 | loss: 0.15741 | val_0_auc: 0.98268 |  0:01:35s\n",
            "epoch 31 | loss: 0.11417 | val_0_auc: 0.99368 |  0:01:36s\n",
            "epoch 31 | loss: 0.12375 | val_0_auc: 0.99067 |  0:01:36s\n",
            "epoch 31 | loss: 0.1153  | val_0_auc: 0.99187 |  0:01:36s\n",
            "epoch 31 | loss: 0.13642 | val_0_auc: 0.98829 |  0:01:36s\n",
            "epoch 32 | loss: 0.15361 | val_0_auc: 0.98398 |  0:01:38s\n",
            "epoch 32 | loss: 0.10683 | val_0_auc: 0.99347 |  0:01:38s\n",
            "epoch 32 | loss: 0.12546 | val_0_auc: 0.99063 |  0:01:39s\n",
            "epoch 32 | loss: 0.11689 | val_0_auc: 0.99148 |  0:01:39s\n",
            "epoch 32 | loss: 0.13894 | val_0_auc: 0.98909 |  0:01:39s\n",
            "epoch 33 | loss: 0.14718 | val_0_auc: 0.98443 |  0:01:41s\n",
            "epoch 33 | loss: 0.09869 | val_0_auc: 0.99496 |  0:01:41s\n",
            "epoch 33 | loss: 0.1217  | val_0_auc: 0.99042 |  0:01:42s\n",
            "epoch 33 | loss: 0.11271 | val_0_auc: 0.9923  |  0:01:42s\n",
            "epoch 33 | loss: 0.12817 | val_0_auc: 0.98983 |  0:01:42s\n",
            "epoch 34 | loss: 0.14348 | val_0_auc: 0.9861  |  0:01:44s\n",
            "epoch 34 | loss: 0.09293 | val_0_auc: 0.99568 |  0:01:44s\n",
            "epoch 34 | loss: 0.13348 | val_0_auc: 0.98902 |  0:01:45s\n",
            "epoch 34 | loss: 0.11025 | val_0_auc: 0.99271 |  0:01:45s\n",
            "epoch 34 | loss: 0.12424 | val_0_auc: 0.99071 |  0:01:45s\n",
            "epoch 35 | loss: 0.14044 | val_0_auc: 0.98593 |  0:01:47s\n",
            "epoch 35 | loss: 0.08705 | val_0_auc: 0.9961  |  0:01:47s\n",
            "epoch 35 | loss: 0.12922 | val_0_auc: 0.98995 |  0:01:48s\n",
            "epoch 35 | loss: 0.10666 | val_0_auc: 0.99372 |  0:01:48s\n",
            "epoch 35 | loss: 0.12102 | val_0_auc: 0.99172 |  0:01:48s\n",
            "epoch 36 | loss: 0.13825 | val_0_auc: 0.98796 |  0:01:50s\n",
            "epoch 36 | loss: 0.08552 | val_0_auc: 0.99671 |  0:01:51s\n",
            "epoch 36 | loss: 0.12192 | val_0_auc: 0.99182 |  0:01:51s\n",
            "epoch 36 | loss: 0.10488 | val_0_auc: 0.99252 |  0:01:52s\n",
            "epoch 36 | loss: 0.11418 | val_0_auc: 0.99301 |  0:01:52s\n",
            "epoch 37 | loss: 0.13809 | val_0_auc: 0.98821 |  0:01:54s\n",
            "epoch 37 | loss: 0.07951 | val_0_auc: 0.997   |  0:01:55s\n",
            "epoch 37 | loss: 0.11735 | val_0_auc: 0.99289 |  0:01:56s\n",
            "epoch 37 | loss: 0.10916 | val_0_auc: 0.99228 |  0:01:56s\n",
            "epoch 37 | loss: 0.10658 | val_0_auc: 0.99387 |  0:01:56s\n",
            "epoch 38 | loss: 0.13404 | val_0_auc: 0.98885 |  0:01:58s\n",
            "epoch 38 | loss: 0.0726  | val_0_auc: 0.99755 |  0:01:59s\n",
            "epoch 38 | loss: 0.10891 | val_0_auc: 0.99347 |  0:01:59s\n",
            "epoch 38 | loss: 0.1074  | val_0_auc: 0.99298 |  0:01:59s\n",
            "epoch 38 | loss: 0.09773 | val_0_auc: 0.99459 |  0:02:00s\n",
            "epoch 39 | loss: 0.1301  | val_0_auc: 0.98911 |  0:02:02s\n",
            "epoch 39 | loss: 0.06841 | val_0_auc: 0.99803 |  0:02:02s\n",
            "epoch 39 | loss: 0.10705 | val_0_auc: 0.99353 |  0:02:03s\n",
            "epoch 39 | loss: 0.09984 | val_0_auc: 0.99417 |  0:02:03s\n",
            "epoch 39 | loss: 0.10037 | val_0_auc: 0.99424 |  0:02:03s\n",
            "epoch 40 | loss: 0.12652 | val_0_auc: 0.98982 |  0:02:05s\n",
            "epoch 40 | loss: 0.0665  | val_0_auc: 0.99823 |  0:02:06s\n",
            "epoch 40 | loss: 0.1029  | val_0_auc: 0.99468 |  0:02:06s\n",
            "epoch 40 | loss: 0.0966  | val_0_auc: 0.99515 |  0:02:07s\n",
            "epoch 40 | loss: 0.09656 | val_0_auc: 0.99478 |  0:02:07s\n",
            "epoch 41 | loss: 0.12355 | val_0_auc: 0.99023 |  0:02:09s\n",
            "epoch 41 | loss: 0.06238 | val_0_auc: 0.99851 |  0:02:10s\n",
            "epoch 41 | loss: 0.09752 | val_0_auc: 0.99558 |  0:02:10s\n",
            "epoch 41 | loss: 0.09528 | val_0_auc: 0.9951  |  0:02:11s\n",
            "epoch 41 | loss: 0.09124 | val_0_auc: 0.99511 |  0:02:11s\n",
            "epoch 42 | loss: 0.12224 | val_0_auc: 0.99183 |  0:02:13s\n",
            "epoch 42 | loss: 0.06065 | val_0_auc: 0.99875 |  0:02:13s\n",
            "epoch 42 | loss: 0.08671 | val_0_auc: 0.9961  |  0:02:14s\n",
            "epoch 42 | loss: 0.09632 | val_0_auc: 0.99507 |  0:02:14s\n",
            "epoch 42 | loss: 0.09202 | val_0_auc: 0.99531 |  0:02:14s\n",
            "epoch 43 | loss: 0.11522 | val_0_auc: 0.99213 |  0:02:16s\n",
            "epoch 43 | loss: 0.0556  | val_0_auc: 0.99866 |  0:02:17s\n",
            "epoch 43 | loss: 0.0889  | val_0_auc: 0.99642 |  0:02:18s\n",
            "epoch 43 | loss: 0.08785 | val_0_auc: 0.99625 |  0:02:18s\n",
            "epoch 43 | loss: 0.08828 | val_0_auc: 0.99529 |  0:02:18s\n",
            "epoch 44 | loss: 0.11073 | val_0_auc: 0.99251 |  0:02:20s\n",
            "epoch 44 | loss: 0.05265 | val_0_auc: 0.99867 |  0:02:21s\n",
            "epoch 44 | loss: 0.08141 | val_0_auc: 0.9968  |  0:02:22s\n",
            "epoch 44 | loss: 0.08232 | val_0_auc: 0.99668 |  0:02:22s\n",
            "epoch 44 | loss: 0.08985 | val_0_auc: 0.99546 |  0:02:22s\n",
            "epoch 45 | loss: 0.11257 | val_0_auc: 0.99256 |  0:02:24s\n",
            "epoch 45 | loss: 0.05036 | val_0_auc: 0.99898 |  0:02:25s\n",
            "epoch 45 | loss: 0.07772 | val_0_auc: 0.99724 |  0:02:26s\n",
            "epoch 45 | loss: 0.07504 | val_0_auc: 0.99726 |  0:02:26s\n",
            "epoch 45 | loss: 0.08538 | val_0_auc: 0.99573 |  0:02:26s\n",
            "epoch 46 | loss: 0.10542 | val_0_auc: 0.99389 |  0:02:28s\n",
            "epoch 46 | loss: 0.04931 | val_0_auc: 0.99905 |  0:02:29s\n",
            "epoch 46 | loss: 0.07315 | val_0_auc: 0.99718 |  0:02:30s\n",
            "epoch 46 | loss: 0.07035 | val_0_auc: 0.99782 |  0:02:30s\n",
            "epoch 46 | loss: 0.08374 | val_0_auc: 0.99552 |  0:02:30s\n",
            "epoch 47 | loss: 0.10463 | val_0_auc: 0.99427 |  0:02:32s\n",
            "epoch 47 | loss: 0.04741 | val_0_auc: 0.99938 |  0:02:33s\n",
            "epoch 47 | loss: 0.08219 | val_0_auc: 0.99683 |  0:02:34s\n",
            "epoch 47 | loss: 0.0629  | val_0_auc: 0.99825 |  0:02:34s\n",
            "epoch 47 | loss: 0.095   | val_0_auc: 0.99458 |  0:02:34s\n",
            "epoch 48 | loss: 0.09572 | val_0_auc: 0.99449 |  0:02:36s\n",
            "epoch 48 | loss: 0.04743 | val_0_auc: 0.9994  |  0:02:37s\n",
            "epoch 48 | loss: 0.08783 | val_0_auc: 0.9952  |  0:02:37s\n",
            "epoch 48 | loss: 0.0669  | val_0_auc: 0.9982  |  0:02:37s\n",
            "epoch 48 | loss: 0.09119 | val_0_auc: 0.99569 |  0:02:38s\n",
            "epoch 49 | loss: 0.09496 | val_0_auc: 0.99481 |  0:02:39s\n",
            "epoch 49 | loss: 0.045   | val_0_auc: 0.99931 |  0:02:40s\n",
            "epoch 49 | loss: 0.0875  | val_0_auc: 0.99662 |  0:02:41s\n",
            "epoch 49 | loss: 0.05834 | val_0_auc: 0.99828 |  0:02:41s\n",
            "epoch 49 | loss: 0.08274 | val_0_auc: 0.99646 |  0:02:41s\n",
            "epoch 50 | loss: 0.09376 | val_0_auc: 0.99542 |  0:02:43s\n",
            "epoch 50 | loss: 0.0427  | val_0_auc: 0.99951 |  0:02:44s\n",
            "epoch 50 | loss: 0.07855 | val_0_auc: 0.99722 |  0:02:45s\n",
            "\n",
            "Early stopping occurred at epoch 50 with best_epoch = 45 and best_val_0_auc = 0.99724\n",
            "epoch 50 | loss: 0.06147 | val_0_auc: 0.99819 |  0:02:45s\n",
            "epoch 50 | loss: 0.07524 | val_0_auc: 0.99691 |  0:02:45s\n",
            "epoch 51 | loss: 0.08919 | val_0_auc: 0.99532 |  0:02:46s\n",
            "epoch 51 | loss: 0.04661 | val_0_auc: 0.99932 |  0:02:47s\n",
            "epoch 51 | loss: 0.05807 | val_0_auc: 0.99894 |  0:02:48s\n",
            "epoch 51 | loss: 0.07418 | val_0_auc: 0.99722 |  0:02:48s\n",
            "epoch 52 | loss: 0.0936  | val_0_auc: 0.99585 |  0:02:50s\n",
            "epoch 52 | loss: 0.05694 | val_0_auc: 0.99788 |  0:02:51s\n",
            "epoch 52 | loss: 0.05119 | val_0_auc: 0.99895 |  0:02:51s\n",
            "epoch 52 | loss: 0.0754  | val_0_auc: 0.99666 |  0:02:51s\n",
            "epoch 53 | loss: 0.0884  | val_0_auc: 0.99613 |  0:02:53s\n",
            "epoch 53 | loss: 0.05349 | val_0_auc: 0.99934 |  0:02:54s\n",
            "epoch 53 | loss: 0.06385 | val_0_auc: 0.99789 |  0:02:54s\n",
            "epoch 53 | loss: 0.07787 | val_0_auc: 0.99678 |  0:02:54s\n",
            "epoch 54 | loss: 0.08852 | val_0_auc: 0.99623 |  0:02:56s\n",
            "epoch 54 | loss: 0.04393 | val_0_auc: 0.99945 |  0:02:57s\n",
            "epoch 54 | loss: 0.0623  | val_0_auc: 0.99842 |  0:02:57s\n",
            "epoch 54 | loss: 0.07691 | val_0_auc: 0.99714 |  0:02:58s\n",
            "epoch 55 | loss: 0.08505 | val_0_auc: 0.99707 |  0:02:59s\n",
            "epoch 55 | loss: 0.04502 | val_0_auc: 0.9992  |  0:03:00s\n",
            "\n",
            "Early stopping occurred at epoch 55 with best_epoch = 50 and best_val_0_auc = 0.99951\n",
            "epoch 55 | loss: 0.05325 | val_0_auc: 0.99836 |  0:03:00s\n",
            "epoch 55 | loss: 0.0701  | val_0_auc: 0.99741 |  0:03:00s\n",
            "epoch 56 | loss: 0.08253 | val_0_auc: 0.99722 |  0:03:02s\n",
            "epoch 56 | loss: 0.0542  | val_0_auc: 0.999   |  0:03:03s\n",
            "epoch 56 | loss: 0.07116 | val_0_auc: 0.99777 |  0:03:03s\n",
            "epoch 57 | loss: 0.07569 | val_0_auc: 0.9978  |  0:03:04s\n",
            "epoch 57 | loss: 0.05066 | val_0_auc: 0.99915 |  0:03:05s\n",
            "epoch 57 | loss: 0.06549 | val_0_auc: 0.99794 |  0:03:05s\n",
            "epoch 58 | loss: 0.07675 | val_0_auc: 0.99739 |  0:03:06s\n",
            "epoch 58 | loss: 0.0425  | val_0_auc: 0.99938 |  0:03:07s\n",
            "epoch 58 | loss: 0.06758 | val_0_auc: 0.99829 |  0:03:07s\n",
            "epoch 59 | loss: 0.07468 | val_0_auc: 0.99756 |  0:03:08s\n",
            "epoch 59 | loss: 0.03897 | val_0_auc: 0.99951 |  0:03:09s\n",
            "epoch 59 | loss: 0.05656 | val_0_auc: 0.9987  |  0:03:09s\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 85\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# 4) 실행\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### TabNet ###\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m evaluate(pipe_tabnet, df_tr, y_train, df_te, y_test, thresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n",
            "Cell \u001b[0;32mIn[17], line 44\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(pipe, X_tr, y_tr, X_te, y_te, thresh)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parallel_backend\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreading\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 44\u001b[0m     y_val_proba \u001b[38;5;241m=\u001b[39m cross_val_predict(\n\u001b[1;32m     45\u001b[0m         pipe, X_tr, y_tr,\n\u001b[1;32m     46\u001b[0m         cv\u001b[38;5;241m=\u001b[39mcv, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     47\u001b[0m     )[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     49\u001b[0m val_pr  \u001b[38;5;241m=\u001b[39m average_precision_score(y_tr, y_val_proba)\n\u001b[1;32m     50\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m (y_val_proba \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m thresh)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:1247\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m-> 1247\u001b[0m predictions \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m   1248\u001b[0m     delayed(_fit_and_predict)(\n\u001b[1;32m   1249\u001b[0m         clone(estimator),\n\u001b[1;32m   1250\u001b[0m         X,\n\u001b[1;32m   1251\u001b[0m         y,\n\u001b[1;32m   1252\u001b[0m         train,\n\u001b[1;32m   1253\u001b[0m         test,\n\u001b[1;32m   1254\u001b[0m         routed_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[1;32m   1255\u001b[0m         method,\n\u001b[1;32m   1256\u001b[0m     )\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m splits\n\u001b[1;32m   1258\u001b[0m )\n\u001b[1;32m   1260\u001b[0m inv_test_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1261\u001b[0m inv_test_indices[test_indices] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[1;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[1;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[1;32m   1799\u001b[0m     ):\n\u001b[0;32m-> 1800\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 60 | loss: 0.07131 | val_0_auc: 0.99766 |  0:03:11s\n",
            "epoch 60 | loss: 0.04112 | val_0_auc: 0.99949 |  0:03:12s\n",
            "epoch 60 | loss: 0.05249 | val_0_auc: 0.99882 |  0:03:12s\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from imblearn.pipeline       import Pipeline\n",
        "from imblearn.ensemble       import BalancedRandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection  import StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics          import (\n",
        "    classification_report,\n",
        "    average_precision_score,\n",
        "    recall_score,\n",
        "    precision_score\n",
        ")\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from torch.optim import Adam as TorchAdam\n",
        "\n",
        "# 0) 준비된 데이터: df_tr, df_te, y_train, y_test\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "SM = BorderlineSMOTE(sampling_strategy=0.3, kind='borderline-1', random_state=42)\n",
        "\n",
        "# 1) TabNet용 sklearn 래퍼 (에포크 늘리고 얼리스탑 patience 조정)\n",
        "class TabNetSklearn(TabNetClassifier):\n",
        "    def fit(self, X, y, **kwargs):\n",
        "        X_np = X.values if hasattr(X, \"values\") else X\n",
        "        y_np = y.values if hasattr(y, \"values\") else y\n",
        "        super().fit(\n",
        "            X_np, y_np,\n",
        "            eval_set=[(X_np, y_np)],\n",
        "            max_epochs=100,         # 최대 2000 에포크까지 학습\n",
        "            patience=5,            # 50 에포크 동안 개선 없으면 얼리스탑\n",
        "            batch_size=1024,\n",
        "            virtual_batch_size=128,\n",
        "            **kwargs\n",
        "        )\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        X_np = X.values if hasattr(X, \"values\") else X\n",
        "        return super().predict_proba(X_np)\n",
        "\n",
        "# 2) 평가 함수 (변경 없음)\n",
        "def evaluate(pipe, X_tr, y_tr, X_te, y_te, thresh=0.5):\n",
        "    from joblib import parallel_backend\n",
        "    with parallel_backend('threading', n_jobs=-1):\n",
        "        y_val_proba = cross_val_predict(\n",
        "            pipe, X_tr, y_tr,\n",
        "            cv=cv, method='predict_proba', n_jobs=-1\n",
        "        )[:,1]\n",
        "\n",
        "    val_pr  = average_precision_score(y_tr, y_val_proba)\n",
        "    y_val_pred = (y_val_proba >= thresh).astype(int)\n",
        "    print(\"===== Validation (5-fold) =====\")\n",
        "    print(f\"PR AUC   : {val_pr:.4f}\")\n",
        "    print(f\"Recall   : {recall_score(y_tr, y_val_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_tr, y_val_pred):.4f}\")\n",
        "    print(classification_report(y_tr, y_val_pred, digits=4))\n",
        "\n",
        "    pipe.fit(X_tr, y_tr)\n",
        "    y_test_proba = pipe.predict_proba(X_te)[:,1]\n",
        "    y_test_pred  = (y_test_proba >= thresh).astype(int)\n",
        "    test_pr  = average_precision_score(y_te, y_test_proba)\n",
        "    print(\"===== Test =====\")\n",
        "    print(f\"PR AUC   : {test_pr:.4f}\")\n",
        "    print(f\"Recall   : {recall_score(y_te, y_test_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_te, y_test_pred):.4f}\")\n",
        "    print(classification_report(y_te, y_test_pred, digits=4))\n",
        "\n",
        "# 3) 파이프라인 정의 (변경 없음)\n",
        "pipe_tabnet = Pipeline([\n",
        "    ('smote',    SM),\n",
        "    ('feat_sel', SelectFromModel(\n",
        "        estimator=BalancedRandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        threshold=-np.inf, prefit=False\n",
        "    )),\n",
        "    ('clf',      TabNetSklearn(\n",
        "                     n_d=16, n_a=16, n_steps=5,\n",
        "                     gamma=1.3,\n",
        "                     optimizer_fn=TorchAdam,\n",
        "                     optimizer_params=dict(lr=2e-2),\n",
        "                     mask_type='entmax'\n",
        "                 ))\n",
        "])\n",
        "\n",
        "# 4) 실행\n",
        "print(\"### TabNet ###\")\n",
        "evaluate(pipe_tabnet, df_tr, y_train, df_te, y_test, thresh=0.5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 5 : LSTM"
      ],
      "metadata": {
        "id": "08UHFormnWiz"
      },
      "id": "08UHFormnWiz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78c00340",
      "metadata": {
        "id": "78c00340"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data_utils\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics import (\n",
        "    classification_report, average_precision_score,\n",
        "    recall_score, precision_score\n",
        ")\n",
        "from joblib import parallel_backend\n",
        "\n",
        "# ------------------------------\n",
        "# 1. LSTMClassifier 정의\n",
        "# ------------------------------\n",
        "class LSTMClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, input_size, hidden_size=64, num_layers=1, epochs=10,\n",
        "                 batch_size=64, lr=1e-3, device=None):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model = None\n",
        "\n",
        "    def _build_model(self):\n",
        "        class LSTMNet(nn.Module):\n",
        "            def __init__(self, input_size, hidden_size, num_layers):\n",
        "                super().__init__()\n",
        "                self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "                self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "            def forward(self, x):\n",
        "                out, _ = self.lstm(x)\n",
        "                return torch.sigmoid(self.fc(out[:, -1, :]))\n",
        "\n",
        "        return LSTMNet(self.input_size, self.hidden_size, self.num_layers).to(self.device)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if hasattr(X, \"values\"):\n",
        "            X = X.values\n",
        "        if hasattr(y, \"values\"):\n",
        "            y = y.values\n",
        "\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(1).to(self.device)\n",
        "        y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1).to(self.device)\n",
        "\n",
        "        dataset = data_utils.TensorDataset(X_tensor, y_tensor)\n",
        "        loader = data_utils.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        self.model = self._build_model()\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        criterion = nn.BCELoss()\n",
        "\n",
        "        self.model.train()\n",
        "        for _ in range(self.epochs):\n",
        "            for xb, yb in loader:\n",
        "                optimizer.zero_grad()\n",
        "                pred = self.model(xb)\n",
        "                loss = criterion(pred, yb)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if hasattr(X, \"values\"):\n",
        "            X = X.values\n",
        "\n",
        "        self.model.eval()\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(1).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            probs = self.model(X_tensor).squeeze().cpu().numpy()\n",
        "        return np.vstack([1 - probs, probs]).T\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Stratified KFold & SMOTE\n",
        "# ------------------------------\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "SM = BorderlineSMOTE(sampling_strategy=0.3, kind='borderline-1', random_state=42)\n",
        "\n",
        "# ------------------------------\n",
        "# 3. LSTM 파이프라인 정의\n",
        "# ------------------------------\n",
        "pipe_lstm_top50 = Pipeline([\n",
        "    ('smote', SM),\n",
        "    ('feat_sel', SelectFromModel(\n",
        "        estimator=BalancedRandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        max_features=50,\n",
        "        threshold=-np.inf,\n",
        "        prefit=False\n",
        "    )),\n",
        "    ('clf', LSTMClassifier(input_size=50, epochs=10))\n",
        "])\n",
        "\n",
        "# ------------------------------\n",
        "# 4. 평가 함수\n",
        "# ------------------------------\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    average_precision_score, classification_report,\n",
        "    precision_score, recall_score\n",
        ")\n",
        "\n",
        "def evaluate_manual_cv(pipe, X_tr, y_tr, X_te, y_te, thresh=0.5, n_splits=5):\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    val_probs = np.zeros(len(X_tr))\n",
        "    val_preds = np.zeros(len(X_tr))\n",
        "\n",
        "    for train_idx, val_idx in skf.split(X_tr, y_tr):\n",
        "        X_train_fold, X_val_fold = X_tr.iloc[train_idx], X_tr.iloc[val_idx]\n",
        "        y_train_fold, y_val_fold = y_tr.iloc[train_idx], y_tr.iloc[val_idx]\n",
        "\n",
        "        pipe.fit(X_train_fold, y_train_fold)\n",
        "        val_proba = pipe.predict_proba(X_val_fold)[:, 1]\n",
        "        val_probs[val_idx] = val_proba\n",
        "        val_preds[val_idx] = (val_proba >= thresh).astype(int)\n",
        "\n",
        "    print(\"===== Validation (manual CV) =====\")\n",
        "    print(f\"PR AUC   : {average_precision_score(y_tr, val_probs):.4f}\")\n",
        "    print(f\"Recall   : {recall_score(y_tr, val_preds):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_tr, val_preds):.4f}\")\n",
        "    print(classification_report(y_tr, val_preds, digits=4))\n",
        "\n",
        "    pipe.fit(X_tr, y_tr)\n",
        "    y_test_proba = pipe.predict_proba(X_te)[:, 1]\n",
        "    y_test_pred = (y_test_proba >= thresh).astype(int)\n",
        "\n",
        "    print(\"===== Test =====\")\n",
        "    print(f\"PR AUC   : {average_precision_score(y_te, y_test_proba):.4f}\")\n",
        "    print(f\"Recall   : {recall_score(y_te, y_test_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_te, y_test_pred):.4f}\")\n",
        "    print(classification_report(y_te, y_test_pred, digits=4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd02df3b",
      "metadata": {
        "id": "cd02df3b",
        "outputId": "bacf7eb3-e3cb-4bb9-de12-c9d01b42ecd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Validation (manual CV) =====\n",
            "PR AUC   : 0.2435\n",
            "Recall   : 0.3143\n",
            "Precision: 0.2689\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9798    0.9749    0.9773     13115\n",
            "           1     0.2689    0.3143    0.2898       385\n",
            "\n",
            "    accuracy                         0.9561     13500\n",
            "   macro avg     0.6243    0.6446    0.6336     13500\n",
            "weighted avg     0.9595    0.9561    0.9577     13500\n",
            "\n",
            "===== Test =====\n",
            "PR AUC   : 0.3251\n",
            "Recall   : 0.3854\n",
            "Precision: 0.2984\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9819    0.9735    0.9776      3279\n",
            "           1     0.2984    0.3854    0.3364        96\n",
            "\n",
            "    accuracy                         0.9567      3375\n",
            "   macro avg     0.6401    0.6794    0.6570      3375\n",
            "weighted avg     0.9624    0.9567    0.9594      3375\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_manual_cv(pipe_lstm_top50, df_tr, y_train, df_te, y_test, thresh=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 6 - FT-Transformer"
      ],
      "metadata": {
        "id": "wbHQOt5hneHf"
      },
      "id": "wbHQOt5hneHf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffdabb30",
      "metadata": {
        "id": "ffdabb30"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data_utils\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "# ------------------------------\n",
        "# FTTransformerClassifier 정의\n",
        "# ------------------------------\n",
        "class FTTransformerClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, input_size, n_blocks=2, n_heads=4, d_token=64,\n",
        "                 batch_size=64, epochs=10, lr=1e-3, device=None):\n",
        "        self.input_size = input_size\n",
        "        self.n_blocks = n_blocks\n",
        "        self.n_heads = n_heads\n",
        "        self.d_token = d_token\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.lr = lr\n",
        "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model = None\n",
        "\n",
        "    def _build_model(self):\n",
        "        class TransformerBlock(nn.Module):\n",
        "            def __init__(self, d_token, n_heads):\n",
        "                super().__init__()\n",
        "                self.attn = nn.MultiheadAttention(d_token, n_heads, batch_first=True)\n",
        "                self.norm1 = nn.LayerNorm(d_token)\n",
        "                self.ff = nn.Sequential(\n",
        "                    nn.Linear(d_token, d_token * 4),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(d_token * 4, d_token)\n",
        "                )\n",
        "                self.norm2 = nn.LayerNorm(d_token)\n",
        "\n",
        "            def forward(self, x):\n",
        "                attn_out, _ = self.attn(x, x, x)\n",
        "                x = self.norm1(x + attn_out)\n",
        "                ff_out = self.ff(x)\n",
        "                return self.norm2(x + ff_out)\n",
        "\n",
        "        class FTTransformer(nn.Module):\n",
        "            def __init__(self, input_size, d_token, n_heads, n_blocks):\n",
        "                super().__init__()\n",
        "                self.input_proj = nn.Linear(input_size, d_token)\n",
        "                self.blocks = nn.Sequential(*[\n",
        "                    TransformerBlock(d_token, n_heads) for _ in range(n_blocks)\n",
        "                ])\n",
        "                self.cls = nn.Linear(d_token, 1)\n",
        "\n",
        "            def forward(self, x):\n",
        "                x = self.input_proj(x)  # [B, 1, d_token]\n",
        "                x = self.blocks(x)\n",
        "                return torch.sigmoid(self.cls(x[:, 0, :]))\n",
        "\n",
        "        return FTTransformer(self.input_size, self.d_token, self.n_heads, self.n_blocks).to(self.device)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if hasattr(X, \"values\"):\n",
        "            X = X.values\n",
        "        if hasattr(y, \"values\"):\n",
        "            y = y.values\n",
        "\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(1).to(self.device)\n",
        "        y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1).to(self.device)\n",
        "\n",
        "        dataset = data_utils.TensorDataset(X_tensor, y_tensor)\n",
        "        loader = data_utils.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        self.model = self._build_model()\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "        criterion = nn.BCELoss()\n",
        "\n",
        "        self.model.train()\n",
        "        for _ in range(self.epochs):\n",
        "            for xb, yb in loader:\n",
        "                optimizer.zero_grad()\n",
        "                pred = self.model(xb)\n",
        "                loss = criterion(pred, yb)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if hasattr(X, \"values\"):\n",
        "            X = X.values\n",
        "\n",
        "        self.model.eval()\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(1).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            probs = self.model(X_tensor).squeeze().cpu().numpy()\n",
        "        return np.vstack([1 - probs, probs]).T\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87b92ccd",
      "metadata": {
        "id": "87b92ccd"
      },
      "outputs": [],
      "source": [
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# SMOTE 및 feature selection 설정은 기존과 동일\n",
        "pipe_ft_top50 = Pipeline([\n",
        "    ('smote', BorderlineSMOTE(sampling_strategy=0.3, kind='borderline-1', random_state=42)),\n",
        "    ('feat_sel', SelectFromModel(\n",
        "        estimator=BalancedRandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        max_features=50,\n",
        "        threshold=-np.inf,\n",
        "        prefit=False\n",
        "    )),\n",
        "    ('clf', FTTransformerClassifier(input_size=50, epochs=10))\n",
        "])\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    classification_report, average_precision_score,\n",
        "    precision_score, recall_score\n",
        ")\n",
        "\n",
        "def evaluate_manual_cv(pipe, X_tr, y_tr, X_te, y_te, thresh=0.5, n_splits=5):\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    val_probs = np.zeros(len(X_tr))\n",
        "    val_preds = np.zeros(len(X_tr))\n",
        "\n",
        "    for train_idx, val_idx in skf.split(X_tr, y_tr):\n",
        "        X_train_fold = X_tr.iloc[train_idx]\n",
        "        y_train_fold = y_tr.iloc[train_idx]\n",
        "        X_val_fold = X_tr.iloc[val_idx]\n",
        "        y_val_fold = y_tr.iloc[val_idx]\n",
        "\n",
        "        pipe.fit(X_train_fold, y_train_fold)\n",
        "        proba = pipe.predict_proba(X_val_fold)[:, 1]\n",
        "        val_probs[val_idx] = proba\n",
        "        val_preds[val_idx] = (proba >= thresh).astype(int)\n",
        "\n",
        "    # Validation 성능 출력\n",
        "    print(\"===== Validation (manual CV) =====\")\n",
        "    print(f\"PR AUC   : {average_precision_score(y_tr, val_probs):.4f}\")\n",
        "    print(f\"Recall   : {recall_score(y_tr, val_preds):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_tr, val_preds):.4f}\")\n",
        "    print(f\"F1 Score : {f1_score(y_tr, val_preds):.4f}\")\n",
        "    print(classification_report(y_tr, val_preds, digits=4))\n",
        "\n",
        "    # 전체 학습 후 Test 성능\n",
        "    pipe.fit(X_tr, y_tr)\n",
        "    y_test_proba = pipe.predict_proba(X_te)[:, 1]\n",
        "    y_test_pred = (y_test_proba >= thresh).astype(int)\n",
        "\n",
        "    print(\"===== Test =====\")\n",
        "    print(f\"PR AUC   : {average_precision_score(y_te, y_test_proba):.4f}\")\n",
        "    print(f\"Recall   : {recall_score(y_te, y_test_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_te, y_test_pred):.4f}\")\n",
        "    print(f\"F1 Score : {f1_score(y_te, y_test_pred):.4f}\")\n",
        "    print(classification_report(y_te, y_test_pred, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45d5f031",
      "metadata": {
        "id": "45d5f031",
        "outputId": "79e57444-f176-44c0-bb05-0f44432792db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Validation (manual CV) =====\n",
            "PR AUC   : 0.3767\n",
            "Recall   : 0.5365\n",
            "Precision: 0.3674\n",
            "F1 Score : 0.4361\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9821    0.9649    0.9734     16563\n",
            "           1     0.3674    0.5365    0.4361       630\n",
            "\n",
            "    accuracy                         0.9492     17193\n",
            "   macro avg     0.6747    0.7507    0.7048     17193\n",
            "weighted avg     0.9595    0.9492    0.9537     17193\n",
            "\n",
            "===== Test =====\n",
            "PR AUC   : 0.4037\n",
            "Recall   : 0.5823\n",
            "Precision: 0.3948\n",
            "F1 Score : 0.4706\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9838    0.9660    0.9748      4141\n",
            "           1     0.3948    0.5823    0.4706       158\n",
            "\n",
            "    accuracy                         0.9518      4299\n",
            "   macro avg     0.6893    0.7741    0.7227      4299\n",
            "weighted avg     0.9621    0.9518    0.9562      4299\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_manual_cv(pipe_ft_top50, df_tr, y_train, df_te, y_test, thresh=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 가장 높은 성능을 보이는 LGBM을 활용한 SHAP value 시각화"
      ],
      "metadata": {
        "id": "L1bbd8HInoCa"
      },
      "id": "L1bbd8HInoCa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4400a07",
      "metadata": {
        "id": "d4400a07"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "# 1. LGBM 모델 가져온 후 학습\n",
        "lgbm_model = pipe_lgbm_top50.named_steps['clf']\n",
        "lgbm_model.fit(df_tr, y_train)\n",
        "\n",
        "# 2. SHAP explainer 생성 (Tree 기반 모델 → TreeExplainer 사용)\n",
        "explainer = shap.TreeExplainer(lgbm_model)\n",
        "\n",
        "# 3. SHAP 값 계산 (큰 데이터면 샘플링)\n",
        "X_sample = pd.DataFrame(df_tr, columns=df_tr.columns).sample(n=1000, random_state=42) \\\n",
        "    if len(df_tr) > 1000 else pd.DataFrame(df_tr, columns=df_tr.columns)\n",
        "shap_exp = explainer(X_sample)\n",
        "\n",
        "# SHAP 요약 그래프 (자동 다차원 처리)\n",
        "shap.summary_plot(shap_exp.values, X_sample)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}